\chapter{Parser Architecture}

\label{parser architecture}

XXX REWRITE\@: MERGE CONTENT FROM ELSEWHERE IN THE THESIS AND PAPER\@.

XXX WHEN FINISHED, CHECK ALL REFERENCES TO ENSURE THEY POINT AT THE CORRECT
CHAPTER\@.

To avoid cluttering the explanation of the parser architecture with the
details involved in parsing Postfix log files and the description of the
parser implemented for this project, the two have been separated.  This
chapter presents the architecture designed and developed for this project,
beginning with the overall architecture and design, followed by the three
components of the architecture: Framework, Actions, and Rules, and
finishes by describing the characteristics of this architecture.

This chapter centers on the theoretical, implementation-independent aspects
of the architecture; the practical difficulties of writing a parser for
Postfix log files are covered in detail in \sectionref{Postfix Parser
Implementation}.

\section{Parser Architecture and Design}

\label{parser design}

It should be clear from the earlier Postfix background (\sectionref{postfix
background}) that log files produced by Postfix vary widely from host to
host, depending on the set of restrictions chosen by the administrator.
With this in mind, one of the parser's design aims was to make adding new
rules as easy as possible, to enable administrators to properly parse their
own log files.  To enable this the architecture is divided into three
parts: framework, actions and rules.  Each will be discussed separately,
but first an overview:

\begin{eqlist}

    \item [Framework]  The framework is the structure that actions and
        rules plug into.  It provides the parsing loop, shared data
        storage, loading and validation of rules, storage of results, and
        other support functions.

    \item [Actions] Each action performs the work required to deal with a
        single category of inputs, e.g.\ processing data from rejections.
        Actions are invoked to deal with a log line once it has been
        identified by the rules: actions modify data structures, handle
        complications, and cause data to be saved to the database.

    \item [Rules]  The rules are responsible for classifying inputs; they
        specify the action to invoke and the regex that matches the inputs
        and extracts data.  Rules provide an easily extensible method of
        associating log lines with actions.

\end{eqlist}

For each input the framework tries each rule in turn until it finds a rule
that matches the input, then invokes the action specified by that rule.

\label{why separate rules, actions, and framework?}

Decoupling the parsing rules from their associated actions allows new rules
to be written and tested without requiring modifications to the parser
source code, significantly lowering the barrier to entry for casual users
who need to parse new inputs, e.g.\ part-time systems administrators
attempting to combat and reduce spam; it also allows companies to develop
user-extensible parsers without divulging their source code.  Decoupling
the framework, actions, and rules simplifies all three and creates a clear
separation of functionality: the framework provides services to the
actions, but does not need to perform any tasks specific to the input being
parsed; actions benefit from having services provided by the framework,
freeing them to concentrate on the task of accurately and correctly
processing the information provided by rules; rules handle the low level
details of classifying inputs and extracting data from those inputs.

Separating the rules from the actions and framework makes it possible to
parse new log lines without modifying the core parsing algorithm.  Adding a
new rule with the action to invoke and a regex to match the log lines is
trivial in comparison to understanding a program's entire parser,
identifying the correct location to change, and making the appropriate
changes.  Bear in mind that changes to the parser must be made without
adversely affecting existing parsing, particularly as there may be edge
cases that are not immediately obvious ---
\sectionref{yet-more-aborted-delivery-attempts} describes a complication
that occurs only four times in \numberOFlogFILES{} log files.  Requiring
changes to the parser's source code also complicates upgrades, as the
changes must be preserved during the upgrade, and may clash with changes
made by the developer.  This architecture allows the user to add new rules
without changing the parser, unless the new log lines require functionality
not already provided by the existing actions.  If the new log lines do
require new functionality, new actions can be added to the parser without
modifying existing actions (\sectionref{adding new actions in
implementation} describes how to safely add new actions); only in the rare
event that the new actions require support from other sections of the code
will more extensive changes be required.

There is some similarity between the parser's design and William Wood's
\acronym{ATN}~\cite{atns,nlpip}, used in Computational Linguistics for creating
grammars to parse or generate sentences.  The resemblance between the two
(shown in \tableref{Similarities between ATN and this architecture}) is
accidental, but it is obvious that the two different approaches share a
similar division of responsibilities, despite having different semantics.

% Do Not Reformat!

\begin{table}[ht]
    \caption{Similarities between ATN and this architecture}
    \empty{}\label{Similarities between ATN and this architecture}
    \begin{tabular}[]{lll}
        \tabletopline{}%
        \acronym{ATN}   & Architecture  & Similarity                  \\
        \tablemiddleline{}%
        Networks        & Overall       & Determines the sequence 
                                          of transitions              \\
                        & Algorithm     & or actions that 
                                          constitutes a valid input.  \\
        Transitions     & Actions       & Assembles data and
                                          imposes conditions          \\
                        &               & the input must meet to be
                                          accepted as                 \\
                        &               & valid.                      \\
        Abbreviations   & Rules         & Responsible for 
                                          classifying input.          \\
        \tablebottomline{}%
    \end{tabular}
\end{table}

\section{Framework}

XXX EXTEND FRAMEWORK SECTION\@: EXPAND ON ALL OF THE POINTS IN THE LIST IN
THE NEXT PARAGRAPH\@.

\label{framework in architecture}

The framework takes care of miscellaneous support functions and low level
details of parsing, freeing the programmers writing actions to concentrate
on writing productive code.  It links actions and rules, allowing either to
be improved independently of the other.  It provides shared storage to pass
data between actions, loads and saves state, loads and validates rules,
manages parsing, invokes actions, tracks how often each rule matches to
optimise rule ordering (\sectionref{rule ordering for efficiency}), stores
results of parsing, and miscellaneous other tasks.
Most parsers will require the same basic functionality from the framework,
plus some specialised support functions.  The framework is the core of the
architecture and is deliberately quite simple: the rules deal with the
variation in inputs, and the actions deal with the intricacies and
complications encountered when parsing.

The function that finds the rule matching the input and invokes the
requested action can be expressed in pseudo-code (indentation denoting flow
of control) as:

% DO NOT REFORMAT!

\begin{verbatim}
for each input:
    for each rule defined by the user: 
        if this rule matches the input:
            perform the action specified by the rule
            skip the remaining rules
            process the next input
    warn the user that the input was not parsed
\end{verbatim}

\section{Actions}

\label{actions in architecture}

XXX TO BE WRITTEN --- CHECK THE IMPLEMENTATION SECTION\@.

Each action is a separate procedure written to deal with a particular
category of input, e.g.\ rejections.  The actions are parser-specific: each
parser author will need to write the required actions from scratch unless
extending an existing parser.  It is anticipated that parsers based on this
architecture will have a high ratio of rules to actions, with the aim of
having simpler rules and clearer distinctions between the inputs parsed by
different rules.  

The ability to add special purpose actions to deal with difficulties and
new requirements that are discovered during parser development is one of
the strengths of this architecture.  Instead of writing a single monolithic
function that must be modified to support new behaviour, with all the
attendant risks of adversely affecting the existing parser, when a new
requirement arises an independent action can be written to satisfy it.
Sometimes the new action will require the cooperation of other actions,
e.g.\ to set or check a flag.  There is a possibility of introducing
failure when modifying existing actions in this way, but the modifications
will be smaller and occur less frequently than with a monolithic
architecture, thus failures will be less likely to occur and will be easier
to test for and diagnose.  The architecture can be implemented in an object
oriented style, allowing sub-classes to extend or override actions in
addition to adding new actions; because each action is an independent
procedure, the sub-class need only modify the action it is overriding,
rather than reproducing large chunks of functionality.

During development of the Postfix log parser it became apparent that in
addition to the obvious variety in log lines there were many complications
to be overcome.  Some were the result of deficiencies in Postfix's logging
(some of which were rectified by later versions of Postfix); others were
due to the vagaries of process scheduling, client behaviour, and
administrative actions.  All were successfully accommodated in the Postfix
log parser: adding new actions was enough to overcome several of the
complications; others required modifications to a single existing action to
work around the difficulties; the remainder were resolved by adapting
existing actions to cooperate and exchange extra data (via the framework),
changing their behaviour as appropriate based on that extra data.

Actions may return a modified input line that will be parsed as if read
from the input stream, allowing for a simplified version of cascaded
parsing~\cite{cascaded-parsing}.  This powerful facility allows several
rules and actions to parse a single input, potentially simplifying both
rules and actions.


\section{Rules}

\label{rules in architecture}

XXX TO BE WRITTEN\@.  TAKE CONTENT FROM THE PAPER AND POSSIBLY FROM THE
IMPLEMENTATION SECTION\@.

Rules categorise inputs, specifying both the regex to match against each
input and the action to invoke when the match is successful.  Parsing new
inputs is generally achieved by creating a new rule that pairs an existing
action with a new regex.  Decoupling the rules from the actions and
framework enables other rule management approaches to be used, e.g.\
instead of manually adding new rules, machine learning techniques could be
used to automatically generate new rules.  If this approach was taken the
choice of machine learning technique would be constrained by the size of
typical data sets (see \sectionref{Results} XXX CHECK THIS REFERENCE WHEN
THE RESULTS SECTION IS FINISHED).  Techniques requiring the full data set
when training would be impractical; Instance Based
Learning~\cite{instance-based-learning} techniques that automatically
determine which inputs from the training set are valuable and which inputs
can be discarded might reduce the data required to a manageable size.  A
parser might also dynamically create new rules in response to certain
inputs, e.g.\ diagnostic messages indicating the program which produced the
input being parsed had read a new configuration file.  These avenues of
research and development has not been pursued by the author, but could
easily be undertaken independently.

The architecture does not try to detect overlapping rules: that
responsibility is left to the author of the rules.  Unintentionally
overlapping rules lead to inconsistent parsing and data extraction because
the first matching rule wins, and the order in which rules are tried
against each input might change between parser invocations.  Overlapping
rules are frequently a requirement, allowing a more specific rule to match
some inputs and a more general rule to match the remainder, e.g.\
separating \acronym{SMTP} delivery to specific sites from \acronym{SMTP}
delivery to the rest of the world.  Allowing overlapping rules simplifies
both the general rule and the more specific rule; additionally rules from
different sources can be combined with a minimum of prior cooperation or
modification required.  Overlapping rules should have a priority attribute
to specify their relative ordering; negative priorities may be useful for
catchall rules.

Decoupling the rules from the actions allows external tools to be written
to detect overlapping rules.  Traditional regexes are equivalent in
computational power to \acronym{FA} and can be converted to \acronym{FA},
so regex overlap can be detected by finding a non-empty intersection of two
\acronym{FA}\@.  The standard equation for \acronym{FA} intersection (given
for example in~\cite{intersection-of-NFA-using-Z}) is: $FA1 \cap{} FA2 =
\overline{(\overline{FA1} \cup{} \overline{FA2})}$, which has considerable
computation complexity.  Perl 5.10 regexes are more powerful than
traditional regexes: it is possible to match correctly balanced brackets
nested to an arbitrary depth, e.g.\
\verb!/^[^<>]*(<(?:(?>[^<>]+)|(?1))*>)[^<>]*$/! matches
\verb!z<123<pq<>rs>j<r>ml>s!.  Perl 5.10 regexes can maintain an arbitrary
state stack and are thus equivalent in computational power to \acronym{PDA}
or \acronym{CFL}, so detecting overlap may require calculating the
intersection of two \acronym{PDA} or \acronym{CFL}s.  The intersection of
two \acronym{CFL}s is not closed, i.e.\ the resulting language cannot
always be parsed by a \acronym{CFL}, so intersection may be intractable in
some cases e.g.:
$a^{*}b^{n}c^{n}~\cap~a^{n}b^{n}c^{*}~\rightarrow~a^{n}b^{n}c^{n}$.
Detecting overlap amongst $n$ regexes requires calculating $n(n-1)/2$
intersections, resulting in $O(n^2x)$ complexity, where $O(x)$ is the
complexity of calculating intersection.  This is certainly not a task to be
performed every time the parser is used: detecting overlap amongst the
Postfix log parser's \numberOFrules{} rules would require calculating
\numberOFruleINTERSECTIONS{} intersections.

The framework requires each rule to have \texttt{action} and \texttt{regex}
attributes; each implementation is free to add any additional attributes it
requires.

It is possible to define pathological regexes which fall into two main
categories: regexes that match every input, and regexes that consume
excessive amounts of CPU time during matching.  Defining a regex to match
all inputs is trivial: \verb!/^/! matches the start of every input.
Usually excessive CPU time is consumed when a regex with a lot of
alteration and variable quantifiers fails to match, but successful
matching is generally quite fast (see~\cite{mastering-regular-expressions}
for in-depth discussion).

XXX RULES CAN HAVE CONDITIONS ATTACHED

\label{comparison against context-free grammars}

In context-free grammar terms the parser rules could be described as:

$\text{\textless{}log-line\textgreater{}} \mapsto \text{rule-1} |
\text{rule-2} | \text{rule-3} | \dots | \text{rule-n}$


Rule have certain characteristics that may help in understanding the
parser architecture:

XXX IMPROVE THIS SECTION\@; SHOULD IT BE A SUBSECTION\@?

\begin{itemize}

    \item Rules are annotated with the name of a Postfix program, and will
        only be used when parsing log lines produced by that
        program.

    \item The first matching rule wins: no further rules are tried against
        that log line, but there is a mechanism for prioritising the rules
        so that more specific rules can be tried first.

    \item Rules are completely self-contained and can be understood in
        isolation, without reference to any other rules.

    \item Rule processing time is a linear function of the number of rules.
        XXX IMPROVE THIS\@.

\end{itemize}

\section{Architecture Characteristics}

\label{Architecture characteristics}

\begin{description}

    \item [Matching rules against inputs is simple:]  The first matching
        rule determines the action that will be invoked: there is no
        backtracking to try alternate rules, no attempt is made to pick a
        \textit{best\/} rule.

    \item [Line oriented:]  The architecture is line oriented at present:
        there is no facility for rules to consume more input or push unused
        input back onto the input stream.  This was not a deliberate design
        decision, rather a consequence of the line oriented nature of
        Postfix log files; more flexible approaches could be pursued.

    \item [Context-free rules:]  Rules can not take into account past or
        future inputs.  In context-free grammar terms the parser rules
        could be described as:
        \newline{}$\text{\textless{}input\textgreater{}} \mapsto
        \text{rule-1} | \text{rule-2} | \text{rule-3} | \dots |
        \text{rule-n}$.

    \item [Context-aware actions:] Actions can consult the results (or lack
        of results) of previous actions during execution, providing some
        context sensitivity.  
        
    \item [Cascaded parsing:] Actions can return a modified input to be
        parsed as if read from the input stream, allowing for a simplified
        version of cascaded parsing~\cite{cascaded-parsing}.

    \item [Transduction:]  The architecture can be thought of as
        implementing transduction: it takes data in one form (log files)
        and transforms it to another form (a database); other formats may
        be more suitable for other implementations.

    \item [Similarity to \acronym{NLP}:] \hfill{} \newline{}
        Unlike traditional parsers such as those used when compiling a
        programming language, this architecture does not require a fixed
        grammar specification that inputs must adhere to.  The architecture
        is capable of dealing with interleaved inputs, out of order inputs,
        and ambiguous inputs where heuristics must be applied --- all have
        arisen and been successfully accommodated in the Postfix log
        parser.

\end{description}


\section{Conclusion}

XXX TO BE WRITTEN\@.
