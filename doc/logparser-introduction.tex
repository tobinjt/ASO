\chapter{Introduction}

\label{introduction}

Most mail server administrators will have performed some basic processing
of the log files produced by their mail server at one time or another,
whether it was to debug a problem, explain to a user why their mail is
being rejected, or check if new anti-spam measures are working.  The more
adventurous will have generated statistics to show how successful each of
their anti-spam measures has been in the last week, and possibly even
generated some graphs to clearly illustrate these statistics to management
or users.\footnote{This was the author's first real foray into processing
Postfix log files.}  Very few will have performed in-depth parsing and
analysis of their log files, where the parsing must correlate the log lines
per-connection or per-queueid rather than processing log lines
independently.  One of the barriers to this kind of processing is the
unstructured nature of Postfix log files, where each log line was added on
an ad hoc basis as a requirement was discovered or new functionality was
added.\footnote{A history of all changes made to Postfix is distributed
with the source code, available from
\urlLastChecked{http://www.postfix.org/}{2009/02/23}} Further complication
arises because the set of rejection messages is not fixed: new messages can
be added by the administrator with custom checks; every
\acronym{DNSBL}\footnote{This document is supplied with a glossary, see
\textsection\ref{Glossary}.} returns a different explanatory message;
policy servers may log different messages depending on the characteristics
of the connection.  There are many ways in which the log lines may differ
between servers, even within the same organisation: servers may be
configured differently, or running different versions of Postfix.  This
paper documents the difficult process of parsing Postfix log files,
presenting \parsername{}, a program that parses Postfix log files and
places the resulting data into a database for later use.  The gathered data
can then be used to optimise current anti-spam measures, provide a baseline
to test new anti-spam measures against, or to produce statistics showing
how effective those measures are.  Numerous other uses are possible for
such data: improving server performance by identifying troublesome
destinations and reconfiguring appropriately; identifying regular high
volume uses (e.g.\ customer newsletters) and restricting those uses to
off-peak times; detecting virus outbreaks that propagate via mail; as a
base for billing customers on a shared server.  Preserving the raw data
enables users to develop a multitude of uses far beyond those conceived of
by the author.

\vspace{1em}\noindent\textbf{Layout:}

XXX THIS ALL NEEDS TO BE CHECKED AND UPDATED\@.

Section~\ref{background} provides background information useful in
understanding the thesis, parser, and architecture.

Section~\ref{state of the art review} reviews both the previously published
research in this area and other available Postfix log file parsers,
discussing why they were deemed unsuitable for the task, including why they
could not be improved or expanded upon.

This algorithm requires a database for storing both the rules used when
parsing and the results gleaned from parsing.  The database schema used is
described in \sectionref{database schema}, explaining in detail the tables
used for storing the data gleaned from the log files and the table that
stores the rules.

Section~\ref{rules in architecture} discusses the parsing rules in detail,
explaining the purpose and usage of each field in a rule, referring to an
example rule and sample data it matches successfully against.  The pros and
cons of overlapping rules are considered, including techniques for
detecting unintentional overlaps.  Rule efficiency concerns are discussed,
in particular the optimisations used by the algorithm.  The section
concludes with a description of using the tools provided with the parser to
generate new rules (specifically the regex in each rule) from unparsed log
lines.

Section~\ref{Postfix Parser Implementation} contains the core of the paper,
describing a naive parsing algorithm and the complications initially
encountered that shaped the full algorithm.  A flow chart and a discussion
of the emergent behaviour exhibited by the algorithm accompanies a
comprehensive explanation of the different stages of the initial algorithm.
The framework that actions and rules fit into is documented, then the
actions taken during execution of the algorithm are described, followed by
the process of adding a new action.  The section concludes with an in-depth
description of the further complications discovered, and their solutions
that complete the parser.

Section~\ref{parsing coverage} analyses the coverage the parser achieves
over a set of \numberOFlogFILES{} log files taken from a mail server
handling mail for over 700 users, averaging 8500 mails per day
(\graphref{Mails received per day}).  Coverage is described both
in terms of the fraction of log lines parsed and the fraction of mails and
connections successfully reconstructed by the parsing algorithm; dealing
with false negatives and a discussion of the difficulties in identifying
false positives is also included.  As part of determining the coverage of
the parser a random sampling of log lines was parsed, and the correctness
of the results manually verified.

Section~\ref{limitations and improvements in implementation} lists the
limitations of the algorithm, then suggests some ways of dealing with them,
with the goal of improving parsing and reproduction of the journey a mail
takes through Postfix.

Section~\ref{conclusion} contains the conclusion of the thesis, describing
the results of the research, design, and implementation of the parser.

The bibliography contains references to the resources used in developing
the algorithm, writing the program, and preparing this thesis.  Also
listed are some additional resources expected to be helpful in
understanding \acronym{SMTP}, Postfix, anti-spam techniques, or the thesis.

Appendix~\ref{Glossary} provides a glossary of terms used in the thesis.

Appendix~\ref{Acronyms} provides a list of acronyms used in the thesis.

Appendix~\ref{Postfix Daemons} gives a brief description of Postfix
daemons.

