\section{Parsing Algorithm}

\label{parsing-algorithm}

EMPHASISE THAT THE LOGS CAUSE THE INTERDEPENDENCIES, NOT THE
ARCHITECTURE\@.

Whereas the rules are quite simple and each rule is completely independent
of the other rules, the algorithm is significantly more complicated and
highly internally interdependent.  The algorithm deals with all the
complications of parsing, the eccentricities and oddities of Postfix log
files, presenting the resulting data in a normalised, easy to use
representation.  The algorithm's task is to follow the journey each mail
takes through Postfix, combining the data extracted by rules into a
coherent whole, saving it in a useful and consistent form, and performing
housekeeping duties.

Please refer to \sectionref{parser design} for a discussion of why the
rules, actions and framework have been separated in the parser's design.
In this section algorithm can be taken to mean the combination of framework
and actions.

\subsection{Introduction}

This section covers the following topics:

\begin{itemize}

    \item A high level overview of the algorithm.

    \item The first set of complications encountered: initially obvious
        difficulties which had to be overcome.

    \item A flow chart showing common paths a mail can take through the
        algorithm, a discussion of the emergent behaviour observed in the
        parser, and an explanation of the paths shown in the flow chart.

    \item A brief description of the framework.

    \item The actions the parser makes available to rules are covered in
        detail.

    \item Additional complications which have arisen during the development
        of this parser are documented, the solutions to those
        complications, and where those solutions are implemented in the
        algorithm

\end{itemize}

\subsection{A high level overview}

From the viewpoint of an individual mail passing through the parser the
experience could be summarised as:

\begin{enumerate}

    \item Mail enters the system via \SMTP{} or local submission.

    \item If the mail is rejected, log all data and finish.

    \item Follow the progress of the accepted mail until it is either
        delivered, bounced or deleted, then log all data, and finish.

\end{enumerate}

The framework's high level overview could be expressed as (indentation
denoting flow of control):

\begin{verbatim}
for each line in the input files:
    for each rule defined by the user:
        if this rule matches the input line:
            perform the action specified by the rule
            skip the remaining rules
            process the next input line
    warn the user that the input line was not parsed
\end{verbatim}

Unfortunately both high level views ignore the many complications
encountered.


\subsection{Complications encountered}

XXX DUNNO IF THIS SECTION SHOULD BE HERE\@.  QUEUEID VS PID ISN'T TOO
IMPORTANT\@; CONNECTION REUSE COULD EASILY BE MOVED TO ADDITIONAL
COMPLICATIONS\@; RE-INJECTED MAILS SHOULD PROBABLY BE MOVED TO ADDITIONAL
COMPLICATIONS TOO\@.

\label{complications}

These complications were encountered early in the parser's implementation
and guided its design and development.

\subsubsection{Queueid vs pid}

The mail lacks a queueid until it has been accepted, so log lines must
first be correlated by the \daemon{smtpd} \pid{}, then transition to being
correlated by the queueid.  This is relatively minor, but does require:

\begin{itemize}

    \item Two versions of several functions: \texttt{by\_pid} and
        \texttt{by\_queueid}.

    \item Two state tables to hold the data structure for each connection.

    \item Most importantly: every section of code must know whether it
        needs to lookup the data structures by \pid{} or queueid.

\end{itemize}

\subsubsection{Connection reuse}

\label{connection reuse}

Multiple independent mails may be delivered during one connection: this
requires the algorithm to clone the current data as soon as a mail is
accepted, so that subsequent mails will not trample over each other's data.
This must be done every time a mail is accepted, as it is impossible to
tell in advance which connections will accept multiple mails.  Happily,
once the mail has been accepted log entries will not be correlated by
\pid{} for that mail any more (its queueid will be used instead), so there
is not any ambiguity about which mail a given log line belongs
to.\footnote{Unfortunately this statement is not completely accurate: see
\sectionref{timeouts-during-data-phase} for details.  However in general
there is not any ambiguity about which data structure should be used for a
given log line.}  The original connection will be discarded unsaved when
the client disconnects if it does not have any data worth saving, i.e.\ no
rejections.  One unsolved difficulty is distinguishing between different
groups of rejections, e.g.\ when dealing with the following sequence:

\begin{enumerate}

    \item The client attempts to deliver a mail, but it is rejected.

    \item The client issues the RSET command to reset the session.

    \item The client attempts to deliver another mail, likewise rejected.

\end{enumerate}

There should probably be two different entries in the database resulting
from the above sequence, but currently there will only be one.



\subsubsection{Re-injected mails}

The most difficult complication initially encountered is that locally
addressed mails are not always delivered directly to a mailbox: sometimes
they are addressed to and accepted for a local address but need to be
delivered to one or more remote addresses due to aliases.  When this occurs
a child mail will be injected into the Postfix queue, but without the
explicit logging \daemon{smtpd} or \daemon{postdrop} injected mails have.
Thus the source is not immediately discernible from the log line in which
the mail first appears; from a strictly chronological reading of the log
files it usually appears as if the child mail has appeared from thin air.
Subsequently the parent mail will log the creation of the child mail:

\texttt{3FF7C4317: to=<username@example.com>, relay=local, \newline
delay=0, status=sent (forwarded as 56F5B43FD)}

The child mail has been created with queueid \texttt{56F5B43FD}.  Different
delivery methods result in different log lines:

\begin{description}

    \item [Re-injected for forwarding:] forwarded as 56F5B43FD

    \item [Delivered to a remote \SMTP{} server:] 250 Ok: queued as
        BD07D3C49

    \item [Local delivery:] delivered to command:
        /mail/procmail/bin/procmail -p -t /mail/procmail/etc/procmailrc

\end{description}

Unfortunately, while all log lines from an individual process appear in
chronological order, the order in which log lines from different processes
are interleaved is subject to the vagaries of process scheduling.  In
addition, the first log line belonging to the child mail (the log line
cited above belongs to the parent mail) is logged by \daemon{qmgr}, so the
order also depends on how busy \daemon{qmgr} is.\footnote{Postfix is quite
paranoid about mail delivery, an excellent characteristic for an \MTA{} to
possess, so it will not log that the child has been created until it is
absolutely certain that the mail has been written to disk.}

Because of this the parser cannot complain when it encounters a log line
from \daemon{qmgr} for a previously unseen mail; it must flag the mail as
coming from an unknown origin, and subsequently clear the flag if and when
the origin of the mail becomes clear.  Obviously the parser could omit
checking of where mails originate from, but requiring an explicit source
helps to expose bugs in the parser; such checks helped to identify the
complications described in \sectionref{discarding cleanup lines} and
\sectionref{pickup logging after cleanup}.

Process scheduling can have a still more confusing effect: quite often the
child mail will be created, delivered and entirely finished with
\textbf{before} the parent logs the creation log line!  Thus, mails flagged
as coming from an unknown origin cannot be entered into the database when
their final log line is parsed; instead they must be marked as ready for
entry and subsequently entered by the parent mail once it has been
identified.

\subsection{Flow chart}

\label{flow-chart}

XXX CONSIDER REMOVING PART TWO OF THE FLOW CHART\@: I DON'T THINK THAT
RE-INJECTION IS IMPORTANT ENOUGH TO WARRANT IT\@.  THE EXPLANATION OF
TRACKING (\textsection{}5.4.3) COULD BE MOVED TO ADDITIONAL
COMPLICATIONS\@.

\Figureref{flow chart image part 1} and \figureref{flow
chart image part 2} show the paths the data representing a mail can take
through the parser algorithm.  The flow chart covers the most common paths
only; there are additional, uncommon paths which are excluded for the sake
of clarity; details of the deviations can be found in
\sectionref{additional complications}.

\showgraph{build/logparser-flow-chart-part-1}{Parser flow chart part
1}{flow chart image part 1}

\showgraph{build/logparser-flow-chart-part-2}{Parser flow chart part
2}{flow chart image part 2}

\clearpage

\subsubsection{Mail enters the system}

\label{mail-enters-the-system}

Everything starts off with a mail entering the system, whether by local
submission via \daemon{postdrop} or sendmail, by \SMTP{}, by re-injection
due to forwarding, or internally generated by Postfix.  Local submission is
the simplest case: a queueid is assigned immediately and the sender address
is logged (action: PICKUP\@; flowchart:~2).

\SMTP{} is more complicated:

\begin{enumerate}

    \item First there is a connection from the remote client (action:
        CONNECT\@; flowchart:~1).

    \item This is followed by rejection of sender address, recipient
        addresses, client \IP{} address or hostname, HELO hostname, etc.\
        (action: REJECTION\@; flowchart:~4); acceptance of one or more
        mails (action: CLONE\@; flowchart:~5); or some interleaving of
        both.

    \item The client disconnects (action: DISCONNECT\@; flowchart:~6).  If
        Postfix has rejected any \SMTP{} commands the data will be saved to
        the database; if not there will not be any data to save (any mails
        accepted will already have been cloned so their data is in another
        data structure).

    \item If one or more mails were accepted there will be more log entries
        for those mails later, see \sectionref{mail-delivery}.

\end{enumerate}

Re-injection due to forwarding sadly lacks explicit log lines of its
own;\footnote{Previously discussed in \sectionref{complications},
complication 3.} re-injection is somewhat awkward to explain because it
overlaps both the mail acceptance and mail delivery sections, so discussion
is deferred to \sectionref{tracking re-injected mail}.

Internally generated mails lack any explicit origin in Postfix 2.2.x and
must be detected using heuristics (see
\sectionref{identifying-bounce-notifications} for details).  Bounce
notifications are the primary example of internally generated mails, though
there may be other types.\footnote{Postfix may generate mails to the
administrator when it encounters configuration errors, but such mails are
presumably rare.}

\subsubsection{Mail delivery}

\label{mail-delivery}

The obvious counterpart to mail entering the system is mail leaving the
system, whether by deletion, bouncing, local delivery, or remote delivery.
All four are handled in exactly the same way:

\begin{enumerate}

    \item Postfix will log the sender and recipient addresses separately
        (action: SAVE\_BY\_QUEUEID\@; flowchart:~9).

    \item Sometimes mail is re-injected and the child mail needs to be
        tracked by the parent mail (action: TRACK\@; flowchart:~10) ---
        \sectionref{tracking re-injected mail} discusses this in
        detail.

    \item Eventually the mail will be delivered, bounced, or deleted by the
        administrator (action: COMMIT\@; flowchart:~12).  This is the last
        log line for this particular mail (though it may be indirectly
        referred to if it was re-injected).  If it is neither parent nor
        child of re-injection the data is cleaned up and entered in the
        database (flowchart:~14), then deleted from the state tables.
        Re-injected mails are described in \sectionref{tracking re-injected
        mail}.

\end{enumerate}

It should be reiterated that the actions above happen whether the mail is
delivered to a mailbox, piped to a command, delivered to a remote server,
bounced (due to a mail loop, delivery failure, or five day timeout), or
deleted by the administrator, \textit{unless\/} the mail is either parent
or child of re-injection, as explained in \sectionref{tracking re-injected
mail}.

\subsubsection{Tracking re-injected mail}

\label{tracking re-injected mail}

The crux of the problem is that re-injected mails appear in the log files
without explicit logging indicating their source.  There are two implicit
indications:

\begin{enumerate}

    \item The indicator which more commonly introduces re-injection is when
        \daemon{qmgr} selects a mail with a previously unseen queueid for
        delivery (action: MAIL\_PICKED\_FOR\_DELIVERY\@; flowchart:~3), in
        which case a new data structure will be created for that mail.  The
        mail will be flagged as having unknown origins; this flag should be
        subsequently cleared once the origin has been established.  This
        may also be an indicator that the mail is a bounce notification,
        see \sectionref{identifying-bounce-notifications} for details.

    \item Local delivery re-injects the mail and logs a relayed delivery
        rather than delivering directly to a mailbox or program as it
        usually would (action: TRACK\@; flowchart:~10).\footnote{Relayed
        delivery is performed by the \SMTP{} client; local delivery means
        local to the server, i.e.\ an address the server is final
        destination for.} In this case the mail may already have been
        created (described above) and the unknown origin flag will be
        cleared; if not a new data structure will be created.  In both
        cases the re-injected mail is marked as a child of the original
        mail.  The log line in question is:

        \texttt{3FF7C4317: to=<username@example.com>, relay=local, \newline
        delay=0, status=sent (forwarded as 56F5B43FD)}

        This second indicator always occurs for re-injected mail but
        typically occurs after the first indicator explained above.  This
        is required to tie the parent and child mails together and so is
        central to the process of tracking re-injected mails.

\end{enumerate}

The algorithm for tracking and saving re-injected mail to the database can
finally be described:

\begin{itemize}

    \item If the mail is of unknown origin it is assumed to be a child mail
        whose parent has not yet been identified (action: COMMIT\@;
        flowchart:~15).  Mark the mail as ready for entry in the database
        (flowchart:~16), and wait for the parent to deal with it
        (flowchart:~17).  The mail should not have subsequent log entries;
        only its parent should refer to it.

    \item If the mail is a child mail then it has already been tracked
        (action: COMMIT\@; flowchart:~18): as with all other mail, the data
        is cleaned up, the child is entered in the database
        (flowchart:~19), then deleted from the state tables.  The child
        mail will be removed from the parent mail's list of children
        (flowchart:~20); if this is the last child and the parent has also
        been entered in the database the parent will be deleted from the
        state tables.

    \item The last alternative is that the mail is a parent mail (action:
        COMMIT\@; flowchart:~21).  Regardless of the state of its children
        its data is cleaned up and entered in the database (flowchart:~22).
        The parent may have children which are waiting to be entered in the
        database (flowchart:~23); each of those children's data is cleaned
        up and entered in the database, then deleted from the state tables.
        The parent may also have outstanding children which are not yet
        delivered (flowchart:~24), in which case the parent must wait for
        those children to be finished with.  As soon as the last child is
        deleted from the state tables the parent will also be finished with
        (flowchart:~25), and deleted from the state tables.

\end{itemize}

A parent mail can have multiple children, which may be delivered before or
after the parent mail.

\subsubsection{Emergent behaviour}

\label{Emergent behaviour}

The rules and actions exhibit emergent behaviour~\cite{Wikipedia-Emergence}
which is far more complicated than the behaviour explicitly encoded in the
algorithm.  The top-level parser could be written in pseudo-code like so
(with indentation level indicating flow control):

\begin{verbatim}
for each line in the input files:
    for each rule defined by the user:
        if this rule matches the input line:
            perform the action specified by the rule
            skip the remaining rules
            process the next input line
    warn the user that the input line was not parsed
\end{verbatim}

Yet despite the brevity of the algorithm above the (simplified) flow chart
in \sectionref{flow-chart} contains:

\begin{itemize}

    \item Twenty one states (not including explicit branches).

    \item Three entry points (1, 2, 3).

    \item Five exit points (8, 14, 17, 20, 25).

    \item Five loops (4--4, 4--5--4, 5--5, 9--9, 9--10--9).

    \item Four explicit branches (7, 13, 15, 18); these are decisions taken
        by an action, determining what will happen next to a mail.

    \item Four implicit branches, where the transition is determined by the
        next log line which is processed for that mail, e.g.\ state 1 can
        transition to either state 4 or state 5.  (1--\{4,5\},
        4--\{4,5,6\}, 5--\{4,5,6\}, 9--\{9,10,11,12\})

\end{itemize}

Several more states and corresponding branches are omitted for the sake of
clarity (these extra states are caused by solving the complications
described in \sectionref{additional complications}).

The actions introduce some of the complexity seen in the flow chart: all
explicit branches and the transitions between some stages (19--20,
21--22--23--24) in the second half of the flow chart
(\figureref{flow chart image part 2}) are encoded within the
actions; the transitions between the other stages (16--17, 24--25) in the
second half arise from the interaction between actions

However the transitions between stages in the first half of the flow chart
(\figureref{flow chart image part 1}) are not encoded anywhere in
the parser; the transitions are determined by the ordering of log lines in
the log file.  The complexity of the first 12 stages in the flow chart
emerges from the interaction of simple rules and actions, easing the
process of adding new actions (described in \sectionref{adding new
actions}), as there is no requirement to explicitly insert the action into
an algorithmic version of the flow chart.\footnote{The solution to the
complication in \sectionref{out of order log lines} (out of order log
lines) requires a list of the acceptable combinations of Postfix programs a
mail can pass through; however this does not correspond to the
\textit{parser actions\/} a mail must pass through.  Before that
complication was overcome, i.e.\ for the first half of the development of
this parser, there was nothing in the parser explicitly encoding the states
or paths a mail could take; no other component in the parser has any need
for this flow of data to be specified.}



\subsection{Framework}

\label{framework}

The intermingling of log entries from different mails immediately rules out
the possibility of handling each mail in isolation; the parser must be
capable of handling multiple mails in parallel, each potentially at a
different stage in its journey, without any interference between mails ---
except in the minority of cases where intra-mail interference is required.
The best way to implement this is to maintain state information for every
unfinished mail and manipulate the appropriate mail correctly for each log
line encountered.

This functionality is provided by the framework, which both drives parsing
overall and provides services to the actions it invokes.  The framework is
responsible for loading rules from the database and sanity checking them,
reading log files, matching each rule against the current log line,
invoking the correct action, maintaining state tables, loading and saving
state, displaying a progress indicator, and miscellaneous other tasks.
Actions use services provided by the framework, including storing and
retrieving data in the state tables, extracting and saving data captured by
rules, storage of global data, debugging functions, preparing a mail for
entry in the database, and entering mails in the database.

There is a similarity between this design and the event-driven programming
paradigm commonly used in GUI programs, where one part of the program
responds to events (mouse clicks in a GUI program, log lines being matched
in the parser) and invokes the correct action.

\subsection{Actions in detail}

\label{actions-in-detail}

Each action is passed the same arguments:

\begin{description}

    \item [line] The log line, separated into fields:

        \begin{description}

            \item [timestamp] The time the line was logged at.

            \item [host] The hostname of the server which logged the line.

            \item [program] The name of the program which logged the line.

            \item [pid] The \pid{} of the program which logged the line.

            \item [text] The remainder of the line.

        \end{description}

    \item [rule] The matching rule.

    \item [matches] The fields in the line captured by the rule's \regex{}.

\end{description}

The actions:

\begin{description}

    \item [BOUNCE] Postfix 2.3 and subsequent versions log the creation of
        bounce messages.  This action creates a new mail if necessary; if
        the mail already exists the unknown origin flag will be removed.
        The action also marks the mail as a bounce notification.  To deal
        with complication \sectionref{Further out of order log lines} this
        action checks a cache of recent bounce mails to avoid creating
        bogus bounce mails when lines are logged out of order.

    \item [CLONE] Multiple mails may be accepted on a single connection, so
        each time a mail is accepted the connection's state table entry
        must be cloned and saved in the state tables under its queueid; if
        the original data structure was used then second and subsequent
        mails would overwrite one another's data.

    \item [COMMIT] Enter the data from the mail into the database. Entry
        will be postponed if the mail is a child waiting to be tracked.
        Once entered, the mail will be deleted from the state tables.
        Deletion will be postponed if the mail is the parent of re-injected
        mail.

    \item [CONNECT] Handle a remote client connecting: create a new state
        table entry (indexed by \daemon{smtpd} \pid{}) and save both the
        client hostname and \IP{} address.

    \item [DELETE] Deals with mail deleted using Postfix's administrative
        command \daemon{postsuper}.  This action adds a dummy recipient
        address if required, then invokes the COMMIT action to handle
        adding the mail to the database.  The complication this action
        deals with is described fully in \sectionref{Mail deleted before
        delivery is attempted}.  

    \item [DISCONNECT] Deal with the remote client disconnecting: enter the
        connection in the database, perform any required cleanup, and
        delete the connection from the state tables.  This action deals
        with aborted delivery attempts
        (\sectionref{aborted-delivery-attempts}).

    \item [EXPIRY] If Postfix has not managed to deliver a mail after
        trying for five days it will give up and return the mail to the
        sender.  When this happens the mail will not have a combination of
        Postfix programs which passes the valid combinations check (see
        \sectionref{out of order log lines}).  To ensure that the mail can
        be committed the EXPIRY action sets a flag marking the mail as
        expired; the flag later causes the valid combinations check to be
        skipped, so the mail will be committed.

    \item [IGNORE] This rule just returns successfully; it is used when a
        line needs to be parsed for completeness but does not either
        provide any useful data or require anything to be done.

    \item [MAIL\_PICKED\_FOR\_DELIVERY] This action represents Postfix
        picking a mail from the queue to deliver. This action is used for
        both \daemon{qmgr} and \daemon{cleanup} as it needs to deal with
        out of order log lines; see \sectionref{discarding cleanup lines}
        for details.

    \item [MAIL\_TOO\_LARGE] When a client tries to send a message larger
        than the local server accepts, the mail will be discarded, and the
        client informed.  See TIMEOUT for further discussion; the two are
        handled in exactly the same way.

    \item [PICKUP] The PICKUP action corresponds to the \daemon{pickup}
        service dealing with a locally submitted mail.  Out of order log
        entries may have caused the state table entry to already exist (see
        \sectionref{pickup logging after cleanup}); otherwise it is
        created.  The data extracted from the log line is then saved to the
        state table entry.

    \item [POSTFIX\_RELOAD] When Postfix stops or reloads its configuration
        it kills all \daemon{smtpd} processes,\footnote{Possibly other
        programs are killed also, but the parser is only affected by and
        interested in \daemon{smtpd} processes exiting.} requiring any
        active connections to be cleaned up, entered in the database, and
        deleted from the state tables.

    \item [REJECTION] Deal with Postfix rejecting an \SMTP{} command from
        the remote client: log the rejection with a mail if there is a
        queueid in the log line, or with the connection if not.

    \item [SAVE\_BY\_QUEUEID] Find the correct mail based on the queueid in
        the log line, and save the data extracted by the \regex{} to it.

    \item [SMTPD\_DIED] Sometimes a \daemon{smtpd} dies or exits
        unsuccessfully; the active connection for that \daemon{smtpd} must
        be cleaned up, entered in the database, and deleted from the state
        tables.

    \item [SMTPD\_KILLED] Sometimes an \daemon{smtpd} is killed by a
        signal~\cite{Wikipedia-unix-signals}; the active connection for
        that \daemon{smtpd} must be cleaned up, entered in the database,
        and deleted from the state tables.

    \item [SMTPD\_WATCHDOG] \daemon{smtpd} processes have a watchdog timer
        to deal with unusual situations --- after five hours the timer will
        expire and the \daemon{smtpd} will exit.  This occurs very
        infrequently, as there are many other timeouts which should occur
        in the intervening hours: \DNS{} timeouts, timeouts reading data
        from the client, etc.  The active connection for that
        \daemon{smtpd} must be cleaned up, entered in the database, and
        deleted from the state tables.

    \item [TIMEOUT] The connection timed out so the mail currently being
        transferred must be discarded. The mail may have been accepted, in
        which case there's a data structure to dispose of, or it may not in
        which case there is not.  See
        \sectionref{timeouts-during-data-phase} for the gory details.

    \item [TRACK] Track a mail when it is re-injected for forwarding to
        another mail server; this happens when a local address is aliased
        to a remote address.  TRACK will be called when dealing with the
        parent mail, and will create the child mail if necessary. TRACK
        checks if the child has already been tracked, either by this parent
        or by another parent, and issues appropriate warnings in either
        case.

\end{description}

The distribution of rules per action is shown in
\graphref{Distribution of rules per action}.

\subsection{Adding new actions}

\label{adding new actions}

Adding new actions is not as simple as adding new rules, though care has
been taken in the parser's design and implementation to make adding new
actions as painless as possible.  The implementor writes a subroutine which
accepts the standard arguments given to actions, and registers it as an
action\footnote{The new action must be registered before the rules are
loaded, as it is an error for a rule to reference an unregistered action;
this helps catch mistakes made when adding new rules.} by calling the
framework subroutine add\_actions() with the name of the new action
subroutine as a parameter.  No other work is required on the implementor's
part to integrate the action into the parser; all of their attention and
effort can be focused on the correctness of their action.  The only
negative aspect is that the process involves editing the parser source
code, which makes upgrading to a later version of the parser more
difficult, though by no means impossible.  If the author of the new action
wishes, they can take advantage of the parser's object oriented
implementation~\cite{Wikipedia-object-orientation} by subclassing it and
implementing their changes in the derived class, allowing future upgrading
of the parser with greatly reduced chance of conflicts.\footnote{The real
difference between the two approaches is where the new code is placed.  The
simpler option is to change the parser code directly, but those changes
will then have to be made to subsequent versions of the parser, and as the
scope of the changes increases so does the chance of conflict, or mistakes
when copying the action.  The more time consuming option is to write a
subclass containing the new actions and change the program which invokes
the parser so that it uses the subclass rather than the parser; the changes
required to the program invoking the parser are minor and much less likely
to lead to conflicts when upgrading to future versions of the parser.  An
alternative is to submit new actions to the author of the parser for
inclusion in future versions, resulting in two benefits: the new actions do
not need to be maintained separately, and other users of the parser will
avail of the new functionality.} The action may need to extend the list of
valid combinations described in \sectionref{out of order log lines} if the
addition creates a different set of acceptable programs, but this is
unlikely to occur, as it would require parsing log lines from Postfix
components the parser currently ignores.\footnote{The mail server used for
development does not utilise either the \daemon{lmtp} or \daemon{virtual}
delivery agents, so this parser does not have rules to handle log lines
from those components.  Adding new rules to parse those component's log
lines is a simple process, though if their behaviour differs significantly
from the \daemon{smtp} or \daemon{local} delivery agents new actions may be
required.  The mail server in question is a production mail server handling
mail for a university department; the benefit is that the log files used
exhibit the idiosyncrasies and peculiarities a mail server in the wild must
deal with, but the downside is that significantly altering the
configuration just to log messages from a different Postfix component is
not an option.}


\subsection{Additional complications}

\label{additional complications}

The complications described in this section are listed in the order in
which they were encountered during development of the parser.  Each of
these complications caused the parser to operate incorrectly, generating
either warning messages or leaving mails in the state table.  The frequency
of occurrence is much higher at the start of the list, with the first
complication occurring several orders of magnitude more frequently than the
last.  When deciding which problem to address next, the most common was
always chosen, as resolving the most common problem would yield the biggest
improvement in the parser, prune the greatest number of mails from
the state tables and error messages, and make the remaining problems more
apparent.


\subsubsection{Identifying bounce notifications}

\label{identifying-bounce-notifications}

Postfix 2.2.x (and presumably previous versions) lacks explicit logging
when bounce notifications are generated; suddenly there will be log entries
for a mail which lacks an obvious source.  There are similarities to the
problem of re-injected mails discussed in \sectionref{tracking re-injected
mail}, but unlike the solution described therein bounce notifications do
not eventually have a log line which identifies their source.  Heuristics
must be used to identify bounce notifications, and those heuristics are:

\begin{enumerate}

    \item The sender address is $<>$.

    \item Neither \daemon{smtpd} nor \daemon{pickup} have logged any
        messages associated with the mail, indicating it was generated
        internally by Postfix, not accepted via \SMTP{} or submitted
        locally by \daemon{postdrop} or sendmail.

    \item The message-id has a specific format: \newline
        \texttt{YYYYMMDDhhmmss.queueid@server.hostname} \newline
        e.g.\ \texttt{20070321125732.D168138A1@smtp.example.com}

    \item The queueid in the message-id must be the same as the queueid of
        the mail: this is what distinguishes bounce notifications generated
        locally from bounce notifications which are being re-injected as a
        result of aliasing.  In the latter case the message-id will be
        unchanged from the original bounce notification, and so even if it
        happens to be in the correct format (e.g.\ if it was generated by
        Postfix on this or another server) the queueid in the message-id
        will not match the queueid of the mail.

\end{enumerate}

Once a mail has been identified as a bounce notification, the unknown
origin flag is cleared and the mail can be cleaned up and entered in the
database.

There is a small chance that a mail will be incorrectly identified as a
bounce notification, as the heuristics used may be too broad.  For this to
occur the following conditions would have to be met:

\begin{enumerate}

    \item The mail must have been generated internally by Postfix.

    \item The sender address must be $<>$.

    \item The message-id must have the correct format and match the queueid
        of the mail.  While a mail sent from elsewhere could easily have
        the correct message-id format, the chance that the queueid in the
        message-id would match the queueid of the mail is extremely small.

\end{enumerate}

If a mail is mis-classified as a bounce message it will almost certainly
have been generated internally by Postfix; arguably mis-classification in
this case is a benefit rather than a drawback, as other mails generated
internally by Postfix will be handled correctly.

Postfix 2.3 (and hopefully subsequent versions) log the creation of a
bounce message.

This check is performed during the COMMIT action.

\subsubsection{Aborted delivery attempts}

\label{aborted-delivery-attempts}

Some mail clients behave unexpectedly during the \SMTP{} dialogue: the
client aborts the first delivery attempt after the first recipient is
accepted, then makes a second delivery attempt for the same recipient which
it continues with until delivery is complete.\footnote{Microsoft Outlook is
one client which behaves in this fashion; no attempt has been made to
identify other clients which act in a similar way.}  An example dialogue
exhibiting this behaviour is presented below (lines starting with a three
digit number are sent by the server, the other lines are sent by the
client):

\begin{verbatim}
220 smtp.example.com ESMTP
EHLO client.example.com
250-smtp.example.com
250-PIPELINING
250-SIZE 15240000
250-ENHANCEDSTATUSCODES
250-8BITMIME
250 DSN
MAIL FROM: <sender@example.com>
250 2.1.0 Ok
RCPT TO: <recipient@example.net>
250 2.1.5 Ok
RSET
250 2.0.0 Ok
RSET
250 2.0.0 Ok
MAIL FROM: <sender@example.com>
250 2.1.0 Ok
RCPT TO: <recipient@example.net>
250 2.1.5 Ok
DATA
354 End data with <CR><LF>.<CR><LF>
The mail transfer is not shown.
250 2.0.0 Ok: queued as 880223FA69
QUIT
221 2.0.0 Bye
\end{verbatim}

Once again Postfix does not log a message making the client's behaviour
clear, so once again heuristics are required to identify when this
behaviour occurs.  In this case a list of all mails accepted during a
connection is saved in the connection state, and the accepted mails are
examined when the disconnection action is executed.  Each mail is checked
for the following: 

\begin{itemize}

    \item Are there two or more \daemon{smtpd} log lines?  Does the second
        result have a postfix\_action attribute of ACCEPTED\@?  The first
        two \daemon{smtpd} log lines will be a connection log line and a
        mail acceptance log line (Postfix logs acceptance as soon as the
        first recipient has been accepted).

    \item Is \daemon{smtpd} the only Postfix component that produced a log
        line for this mail?  Every mail which passes normally through
        Postfix will have a \daemon{cleanup} line, and later a
        \daemon{qmgr} log line; lack of a \daemon{cleanup} line is a sure
        sign the mail did not make it too far.  

    \item Does the queueid exist in the state tables?  If not it cannot be
        an aborted delivery attempt.

    \item If there are third and subsequent results, are all their
        postfix\_action attributes equal to INFO\@?  If there are any log
        lines after the first two they should be informational lines only.

\end{itemize}

If all the checks above are successful then the mail is assumed to be an
aborted delivery attempt and is discarded.  There will be no further
entries logged for such mails, so without identifying and discarding them
they accumulate in the state table and will cause clashes if the queueid is
reused.  The mail cannot be entered in the database as the only data
available is the client hostname and \IP{} address, but the database schema
requires many more fields be populated (see \sectionref{connections table}
and \sectionref{results table}).  This heuristic is quite restrictive, and
it appears there is little scope for false positives; if there are any
false positives there will be warnings when the next log line for that mail
is parsed.  False negatives are less likely to be detected: there may be
queueid clashes (and warnings) if mails remain in the state tables after
they should have been removed, otherwise the only way to detect false
negatives is to examine the state tables after each parsing run.

This check is performed in the DISCONNECT action; it requires support in
the CLONE action where a list of cloned connections is maintained.

\subsubsection{Further aborted delivery attempts}

Some mail clients disconnect abruptly if a second or subsequent recipient
is rejected; they may also disconnect after other errors, but such
disconnections are either unimportant or are handled elsewhere in the
parser (\sectionref{timeouts-during-data-phase}).  Sadly, Postfix does not
log a message saying the mail has been discarded, as should be expected by
now.  The checks to identify this happening are:

\begin{itemize}

    \item Is the mail missing its \daemon{cleanup} log message?  Every mail
        which passes through Postfix will have a \daemon{cleanup} line;
        lack of a \daemon{cleanup} line is a sure sign the mail did not
        make it too far.

    \item Were there three or more \daemon{smtpd} log lines for the mail?
        There should be a connection line and a mail accepted line,
        followed by one or more rejection lines.

    \item Is the last \daemon{smtpd} log line a rejection line?

\end{itemize}

These checks are made during the DISCONNECT action: if all checks are
successful then the mail is assumed to have been discarded when the client
disconnected.  There will be no further entries logged for such mails, so
without identifying and entering them in the database immediately they
accumulate in the state table and will cause clashes if the queueid is
reused.

\subsubsection{Timeouts during DATA phase}

\label{timeouts-during-data-phase}

The DATA phase of the \SMTP{} conversation is where the headers and body of
the mail are transferred.  Sometimes there is a timeout or the connection
is lost\footnote{For brevity's sake \textit{timeout\/} will be used
throughout this section, but everything applies equally to lost
connections.} during the DATA phase; when this occurs Postfix will discard
the mail and the parser needs to discard the data associated with that
mail.  It seems more intuitive to save the data to the database, but if a
timeout occurs there is no data available to save; the timeout is recorded
with the connection data instead.

To deal properly with timeouts the parsing algorithm needs to do the
following in the TIMEOUT action:

\begin{enumerate}

    \item Record the timeout and associated data in the connection's
        results.

    \item If no mails have been accepted yet nothing needs to be done; the
        TIMEOUT action ends.  

    \item If one or more recipients have been accepted Postfix will have
        allocated a queueid for the incoming mail, and there will be a mail
        in the state tables which needs to be dealt with.

\end{enumerate}

A timeout may thus apply either to an accepted mail or a rejected mail.  To
distinguish between the two cases the algorithm compares the timestamp of
the last accepted mail against the timestamp of the last line logged by
\daemon{smtpd} for that connection (the TIMEOUT action is dependant on the
CLONE action keeping a list of all mails accepted on each connection).  If
the mail acceptance timestamp is later then the timeout applies to the
just-accepted mail, which will be discarded.  If the \daemon{smtpd}
timestamp is later there was a rejection between the accepted mail and the
timeout: the action assumes that the timeout applies to a rejected delivery
attempt and finishes.  This assumption is not necessarily correct, because
Postfix may have accepted an earlier recipient and rejected a later one, in
which case the timeout applies to the accepted mail, which should be
discarded.  This has not been a problem in practice, though it may be in
future.

This complication is further complicated by the presence of out of order
\daemon{cleanup} lines: see \sectionref{discarding cleanup lines} for
details.

\subsubsection{Discarding cleanup lines}

\label{discarding cleanup lines}

The author has only observed this complication occurring after a timeout,
though there may be other circumstances which trigger it.  Sometimes the
\daemon{cleanup} line is logged after the timeout line; parsing this line
causes the creation of a new state table entry for the queueid in the log
line.  This is incorrect because the line actually belongs to the mail
which has just been discarded; the next log line for that queueid will be
seen when the queueid is reused for a different mail, causing a queueid
clash and the appropriate warning.

In the case where the \daemon{cleanup} line is still pending during the
TIMEOUT action the algorithm updates a global cache of queueids, adding the
queueid and the timestamp from the timeout line.  When the next
\daemon{cleanup} line is parsed for that queueid the cache will be checked
(during the MAIL\_PICKED\_FOR\_DELIVERY action),
and the line will be deemed part of the discarded mail and discarded if it
meets the following requirements:

\begin{itemize}

    \item The queueid must not have been reused yet, i.e.\ there is not an
        entry in the state tables for the queueid.

    \item The timestamp of the \daemon{cleanup} line must be within ten
        minutes of the mail acceptance timestamp.  Timeouts happen after
        five minutes, but some data may have been transferred slowly
        (perhaps because either the client or server is suffering from
        network congestion or rate limiting), and empirical evidence shows
        that ten minutes is not unreasonable; hopefully it is a good
        compromise between false positives and false negatives.

\end{itemize}

The next \daemon{cleanup} line must meet the criteria above for it to be
discarded because not every connection where a timeout occurs will have a
\daemon{cleanup} line logged for it; if the algorithm blindly discarded the
next \daemon{cleanup} line after a TIMEOUT it would in some cases be
mistaken.  Whether or not the next \daemon{cleanup} line is discarded the
queueid will be removed from the cache of timeout queueids when the next
\daemon{pickup} line containing that queueid is parsed.

\subsubsection{Pickup logging after cleanup}

\label{pickup logging after cleanup}

Occasionally the \daemon{pickup} line logged when mail is submitted locally
via sendmail appears later in the log file than the \daemon{cleanup} line
for that mail.  This seems to occur during periods of particularly heavy
load, so is most likely due to process scheduling vagaries.  Normally if
the queueid given in the PICKUP line exists in the state tables a warning
is generated by the \daemon{pickup} action, but if the following conditions
are met it is assumed that the lines were out of order:

\begin{itemize}

    \item The only program which has logged anything thus far for the mail
        is \daemon{cleanup}.

    \item There is less than a five second difference between the
        timestamps of the \daemon{cleanup} and \daemon{pickup} lines.

\end{itemize}

As always with heuristics there may be circumstances in which these
heuristics match incorrectly,  but none have been identified so far.

This complication is dealt with during the PICKUP action.

\subsubsection{Smtpd stops logging}

\label{smtpd stops logging}

Occasionally a \daemon{smtpd} will just stop logging, without an
immediately obvious reason.  After poring over log files for some time
there are several reasons for this infrequent occurrence:

\begin{enumerate}

    \item Postfix is stopped or its configuration is reloaded.  When this
        happens all \daemon{smtpd} processes exit, and all entries in the
        connections state table must be cleaned up, entered in the database
        if there is sufficient data, and deleted.  The queueid state table
        is untouched.

    \item Sometimes a \daemon{smtpd} is killed by a signal (sent by Postfix
        for some reason, by the administrator, or by the OS), so its active
        connection must be cleaned up, entered in the database if there is
        sufficient data, and deleted from the connections state table.

    \item Occasionally a \daemon{smtpd} will exit uncleanly, so the active
        connection must be cleaned up, entered in the database if there is
        sufficient data, and deleted from the connections state table.

\end{enumerate}

The above descriptions appear to cover all situations identified thus far
where a \daemon{smtpd} suddenly stops logging.  In addition to removing an
active connection the last accepted mail may need to be discarded, as
detailed in \sectionref{timeouts-during-data-phase}.

These occurrences are handled by the three actions POSTFIX\_RELOAD,
SMTPD\_DIED and SMTPD\_WATCHDOG\@.

\subsubsection{Out of order log lines}

\label{out of order log lines}

Occasionally a log file will have out of order log lines which cannot be
dealt with by the techniques described in \sectionref{tracking re-injected
mail}, \sectionref{discarding cleanup lines} or \sectionref{pickup logging
after cleanup}.  In the \numberOFlogFILES{} log files used for testing this
occurs only five times in 60,721,709 log lines, but for completeness of the
algorithm it should be dealt with.  The five occurrences in the test log
files have the same characteristics: the \daemon{local} log line showing
delivery to a local mailbox occurs after the \daemon{qmgr} log line showing
removal of the mail from the queue because delivery is completed.  This
causes problems: the mail is not complete, so entry into the database
fails; a new mail is created when the \daemon{local} line is parsed and
remains in the state tables; four warnings are issued per pair of out of
order log lines.

The solution to this problem is to examine the list of programs which have
logged lines for each mail, comparing the list against a table of
known-good combinations of programs (this check is performed during the
COMMIT action).  If the mail's combination is found in the valid list the
mail can be entered in the database; if the combination is not found entry
must be postponed and the mail flagged for later entry.  The
SAVE\_BY\_QUEUEID action checks for that flag and retries entry if it is
found; if the additional log lines have caused the mail to reach a valid
combination entry will proceed, otherwise it must be postponed once more.

The list of valid combinations is explained below.  Every mail will
additionally have log entries from \daemon{cleanup} and \daemon{qmgr}; any
mail may also have log entries from \daemon{bounce}, \daemon{postsuper}, or
both.

\begin{description}

    \item [\daemon{local}:] Local delivery of a bounce notification, or
        local delivery of a forwarded or tracked mail.

    \item [\daemon{local}, \daemon{pickup}:] Mail submitted locally on the
        server, delivered locally on the server.

    \item [\daemon{local}, \daemon{pickup}, \daemon{smtp}:] Locally
        submitted mail, \newline both local and remote delivery.

    \item [\daemon{local}, \daemon{smtp}, \daemon{smtpd}:] Mail accepted
        from a remote client, both local and remote delivery.

    \item [\daemon{local}, \daemon{smtpd}:] Mail accepted from a remote
        client, local delivery only.

    \item [\daemon{pickup}, \daemon{smtp}:] Locally submitted mail, remote
        delivery only.

    \item [\daemon{smtp}:] Remote delivery of forwarded or tracked mail, or
        a bounce notification.

    \item [\daemon{smtp}, \daemon{smtpd}:] Mail accepted from a remote
        client, then remotely delivered (typically relaying mail for
        clients on the local network).

    \item [\daemon{smtpd}, \daemon{postsuper}:] Mail accepted from a remote
        client, then deleted by the administrator before any delivery
        attempt was made (the unwanted mail is typically due to a mail loop
        or joe~job).  Notice that \daemon{postsuper} is required, not
        optional, for this combination.

\end{description}

This check applies to accepted mails only, not to rejected mails.

\subsubsection{Yet more aborted delivery attempts}

\label{yet-more-aborted-delivery-attempts}

The aborted delivery attempts described in
\sectionref{aborted-delivery-attempts} occur frequently, but the aborted
delivery attempts described in this section only occur four times in the
\numberOFlogFILES{} log files used for testing.  The symptoms are the same
as in \sectionref{aborted-delivery-attempts}, except that there
\textit{is\/} a \daemon{cleanup} log line; there does not appear to be
anything in the log file to explain why there are no further log messages.
The only way to detect these mails is to periodically scan all mails in the
state tables, deleting any mails displaying the following characteristics:

\begin{itemize}

    \item The timestamp of the last log line for the mail must be 12 hours
        or more earlier than the last log line parsed.

    \item There must be exactly two \daemon{smtpd} and one \daemon{cleanup}
        log entries for the mail, with no additional log entries.

\end{itemize}

12 hours is a somewhat arbitrary time period, but it is far longer than
Postfix would delay delivery of a mail in the queue.\footnote{This may be a
problem if Postfix is not running for an extended period of time.}  The
state tables are scanned for mails matching the characteristics above each
time the end of a log file is reached, and matching mails are deleted.

\subsubsection{Mail deleted before delivery is attempted}

\label{Mail deleted before delivery is attempted}

Postfix logs the recipient address when delivery of a mail is attempted, so
if delivery has yet to be attempted the parser cannot determine the
recipient address or addresses.  This is a problem when mail is arriving
faster than Postfix can attempt delivery, and the administrator deletes
some of the mail (because it is the result of a mail loop, mail bomb, or
joe~job) before Postfix has had a chance to try to deliver it.  In this
case the recipient address will not have been logged, so a dummy recipient
address needs to be added, as every mail is required to have at least one
recipient.  This complication has been observed in few log files, but
typically when it does occur there will be many instances of it, closely
grouped.  The DELETE action is responsible for handling this complication.

\subsubsection{Further out of order log lines}

\label{Further out of order log lines}

This is yet another complication which only occurs during periods of
extremely high load, when process scheduling vagaries and even hard disk
access times cause strange behaviour.  In this complication bounce
notification mails are created, delivered and deleted from the queue,
\textit{before\/} the log line from \daemon{bounce} is logged.  To deal
with this the COMMIT action maintains a cache of recently committed bounce
notification mails, which the BOUNCE action subsequently checks if the
bounce mail is not already in the state tables. If a mail exists in the
cache under the correct queueid, and its start time is less than ten
seconds before the timestamp of the bounce log line, it is assumed that the
bounce notification mail has already been processed and the BOUNCE action
does not create one.  If the queueid exists it is removed from the cache,
as it has either just been used or it is too old to use in future.  Whether
the BOUNCE action creates a mail or finds one existing in the state tables,
it flags the mail as having been seen by the BOUNCE action; if this flag is
present the COMMIT action will not add the mail to the cache of recent
bounce notification mails.\footnote{This is not required to correctly deal
with the complication, but is an optimisation to reduce memory usage of the
parser; on the occasions the author has observed this action occurring
there have been a huge number of bounce notification mails generated --- if
every bounce notification mail was cached it would dramatically increase
the memory requirements of the parser.}  The cache of bounce notification
mails will be pruned whenever the parser's state is saved, though if the
size of the cache ever becomes a problem it could be pruned periodically to
keep the size in check.

\subsubsection{Mails deleted during delivery}

\label{Mails deleted during delivery}

The administrator can delete mails using \daemon{postsuper}; occasionally
mails in the process of being delivered will be deleted.  This results in
the log lines from the delivery agent (\daemon{local}, \daemon{virtual} or
\daemon{smtp}) appearing in the log file \textit{after\/} the mail has been
removed from the state tables and saved in the database.  The DELETE action
adds deleted mails to a cache, which is checked by the SAVE\_BY\_QUEUEID
action, and the current log line discarded if the following conditions are
met:

\begin{enumerate}

    \item The queueid is not found in the state tables. 

    \item The queueid is found in the cache of deleted mails.

    \item The timestamp of the log line is within 5 minutes of the end time
        of the mail.

\end{enumerate}

Sadly this solution involves discarding some data, but the complication
only arises eight times (tightly grouped in one log file, which is not in
the group used for testing); if this complication occurred more frequently
it might be desirable to find the mail in the database and add the log
line to it.

\subsection{Summary}

This section presented the core of the parser, starting with a very high
level view and the initial complications which arose.  A flow chart showing
the paths a mail may take through the nascent simplified algorithm was
provided, followed by an explanation of those paths, and a discussion of
the parser's emergent behaviour --- the data from the log files creates the
paths in the flow chart, they are not specified anywhere in the parser.
The framework which holds the parser together was covered next, after which
came a description of the current actions provided by the parser, and the
algorithm for analysing unparsed log lines to create \regexes{} for new
rules.  Detecting, diagnosing and defeating complications forms the largest
single portion of this document, mirroring the development of the parser,
The complications are described in the order they were overcome, with
subsequent problems affecting fewer mails (often by an order or magnitude),
though the time required to solve problems increased with each successive
problem.


