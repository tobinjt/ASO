\chapter{Evaluation}

\label{Evaluation}

\renewcommand{\figurename}{Graph}

% Reduce the gap between columns in tables.
\addtolength{\tabcolsep}{-2pt}

This chapter evaluates \parsername{} on two criteria: efficiency, and
coverage of  Postfix log files.  \parsername{} is intended to be used in a
production environment, and must be capable of parsing log files generated
by a high volume mail server in a reasonable time period.  Accurate but
slow parsing is preferable to sloppy but quick parsing, so the goal of
better parser efficiency must be balanced against the requirement for
precise and correct processing of log files.

The performance evaluation begins by describing the characteristics of the
mail server that produced the log files used evaluate the parser's
performance and coverage; the computer that the tests were run on is also
described.  The characteristics of the \numberOFlogFILES{} log files are
described next, with an explanation of why \parsername{} has better
performance with the larger log files in the group.  The effect of using
different rule orderings is explored, and the use of optimal rule ordering
is compared to use of an oracle that allows the parser to use only one rule
when recognising each log line.  When \parsername{} is used by other mail
administrators, they will need to extend the ruleset to parse their own log
lines, so the next section addresses the question of how parser performance
is affected by an increase in the number of rules in the ruleset.  The
penultimate topic to be covered is the simple optimisation of caching the
results of compiling each regex, and the huge effect it has on parser
efficiency.  The performance evaluation concludes by examining where
parsing time is spent: recognition of log lines or their subsequent
processing?

The second criterion the parser is evaluated on is its coverage of Postfix
log files.  This topic consists of two sections: what proportion of log
lines are correctly recognised by the ruleset, and what proportion of mail
delivery attempts are correctly understood and reconstructed by the
actions?  The former is a requirement for the latter to be achieved, and
the latter is important because the data provided by \parsername{} must be
both complete and correct for it to be of use to others.

\section{Parser Efficiency}

\label{parser efficiency}

Efficiency is an obvious concern when the parser routinely needs to parse
large log files.  The server that generated the log files used in testing
this parser accepts approximately 10,000 mails for 700 users each weekday;
\graphref{Mails received per day} and \tableref{Number of mails received
per day: statistics} show that, as expected, far more mails are received on
weekdays than at weekends.  Note that these figures only count mails
received by \acronym{SMTP}, and the mail loops noticeable in later graphs
do not affect the figures.  Median log file size is
\input{build/include-median-file-size}, containing
\input{build/include-median-number-of-log-lines} log lines; large scale
mail servers would have much larger log files.  The mail server in question
is a production mail server handling mail for a university department; the
benefit of using this mail server is that its log files exhibit the
idiosyncrasies and peculiarities a mail server in the wild must deal with,
but the downside is that significantly altering the configuration to
accommodate this project is not an option.

\showgraph{build/graph-mails-received}{Number of mails received via SMTP
per day}{Mails received per day}

\showtable{build/include-mails-received-table}{Number of mails received via
SMTP per day}{Number of mails received per day: statistics}

\begin{table}[thbp]
    \caption{Details of the computer used to generate statistics}
    \empty{}\label{Details of the computer used to generate statistics}
    \centering{}
    \begin{tabular}[]{ll}
        \tabletopline{}%
        Component  & Component in use                                   \\
        \tablemiddleline{}%
        CPU         & One dual core 2.40GHz Intel\textregistered{}
                        Core\texttrademark{}~2 CPU,                     \\
                    & with 32KB L1 cache and 4MB L2 cache.              \\
        RAM         & 2GB 667 MHz DDR RAM\@.                            \\
        Hard disk   & One Seagate Barracuda 7200 RPM 250GB SATA disk.   \\
        \tablebottomline{}%
    \end{tabular}
\end{table}

When generating the timing data used in this section, \numberOFlogFILES{}
log files (totaling \input{build/include-total-size-of-93-log-files},
\numberOFlogLINEShuman{} log lines) were each parsed 10 times, and the mean
parsing time.  The computer used for test runs was a Dell Optiplex 745,
shown in \tableref{Details of the computer used to generate statistics}; it
was dedicated to the task of gathering statistics from test runs, and did
not run any other programs while test runs were in progress.  Saving
results to the database was disabled for the test runs, because that
dominates the run time of the parser, and the tests are aimed at measuring
the speed of \parsername{} rather than the speed of the database and the
disks it is stored on.  Parsing all \numberOFlogFILES{} log files in one
run without saving results to the database took
\input{build/include-full-run-duration}, with mean throughput of
\input{build/include-full-run-throughput}.  In contrast, when saving
results to the database, parsing all \numberOFlogFILES{} log files took
\input{build/include-insert-results-duration}, with mean throughput of
\input{build/include-insert-results-throughput} --- parsing makes up only
\input{build/include-skip-inserting-as-percentage-of-inserting} of the
execution time when saving results to the database.

\subsection{Characteristics Of The Input Log Files}

The \numberOFlogFILES{} log files used when generating statistics have
fairly consistent sizes and contents, except for two groups of log files:
22 \& 62--68.  \Graphref{parsing time vs log file size vs number of log
lines graph} shows the parsing time in seconds, log file size in MB, and
number of log lines in tens of thousands, for each of the
\numberOFlogFILES{} log files.  \Graphref{parsing time vs log file size vs
number of log lines factor} plots both the ratio of log file size vs
parsing time, and the ratio of number of log lines vs parsing time (higher
is more efficient in both cases); \tableref{parsing time vs log file size
vs number of log lines factor table} shows the same ratios for different
groups of log files.  The ratios are quite tightly banded, except they
increase (i.e.\ improve) for log files 22 \& 62--68, despite their larger
than usual size.  Both groups of log files are much larger than usual
because of mail loops caused by users who set up mail forwarding
incorrectly, resulting in a very different distribution of log lines:
normally most log lines are generated by mail delivery attempts from other
hosts, but when the mail loops occurred most of the log lines resulted from
failed delivery of mail generated on the server itself.  The Postfix
components that generated most of the log lines during the mail loops have
fewer associated rules than the Postfix components whose log lines normally
make up the bulk of each log file, so the mean number of rules tried per
log line reduces, as does the mean parsing time per log line.
\Tableref{Number of rules per Postfix component} shows the number of rules
for each Postfix component; \graphref{Mean number of rules used per log
line} shows the drop in the mean number of rules tried per log line for log
files containing a mail loop, and \graphref{Mean number of rules used per
log line for each Postfix component} shows the mean number of rules tried
per log line for each Postfix component.

\showtable{build/include-file-size-and-number-of-log-lines-vs-parsing-time}{Ratio
of log file size and number of log lines to parsing time}{parsing time vs
log file size vs number of log lines factor table}

\showgraph{build/graph-input-size-vs-parsing-time}{Parsing time, log file
size, and number of log lines for \numberOFlogFILES{} log files}{parsing
time vs log file size vs number of log lines graph}

\showgraph{build/graph-input-size-vs-parsing-time-ratio}{Ratio of log file
size and number of log lines to parsing time (higher is more
efficient)}{parsing time vs log file size vs number of log lines factor}

\showgraph{build/graph-average-number-of-rules-tried-per-log-line}{Mean
number of rules used per log line}{Mean number of rules used per log line}

\showgraph{build/graph-average-number-of-rules-tried-per-program}{Mean
number of rules used per log line for each Postfix component}{Mean number
of rules used per log line for each Postfix component}

\begin{table}[thbp]
    \caption{Number of rules per Postfix component}
    \empty{}\label{Number of rules per Postfix component}
    \centering{}
    \begin{tabular}{lr}
        \tabletopline{}%
        Postfix component & Number of rules \\
        \tablemiddleline{}%
        \input{build/include-number-of-rules-per-program}
        \tablebottomline{}%
    \end{tabular}
\end{table}

\FloatBarrier{}

\subsection{Rule Ordering For Efficiency}

\label{rule ordering for efficiency}

\parsernames{} ruleset has \numberOFrules{} rules: the top 10\% recognise
\input{build/include-top-ten-hits}\% of the log lines in the
\numberOFlogFILES{} log files, with the remaining log lines split across
the other 90\% of the rules, as shown in \graphref{rule hits graph}.
Assuming that the distribution of log lines is reasonably consistent over
time, \parsernames{} efficiency should benefit from using rules that
recognise log lines more frequently before it uses rules that recognise log
lines less frequently.  To test this hypothesis, three full test runs were
performed with different rule orderings:

\begin{boldeqlist}

    \item [Optimal]  The most optimal order, according to the hypothesis:
        rules that recognise log lines most often will be tried first.

    \item [Shuffle] This ordering is intended to represent a randomly
        ordered rule set.  The rules will be shuffled once before use and
        will retain that ordering until the parser exits.  Note that the
        ordering will change every time the parser is executed, so 10
        different rule orderings will be generated for each log file in the
        test run.

    \item [Reverse] Hypothetically the worst order: rules that recognise
        log lines most frequently will be tried last.

\end{boldeqlist}

\Graphref{Parsing time of optimal and reverse orderings relative to
shuffled ordering graph} shows the parsing times of optimal and reverse
orderings relative to shuffled ordering; the mean relative parsing times
for different groupings of log files are given in \tableref{Parsing time of
optimal and reverse orderings relative to shuffled ordering table}.  This
optimisation provides a mean reduction in parsing time of
\input{build/include-optimal-ordering-parsing-time-reduction-other-logs}\%
with normal log files,
\input{build/include-optimal-ordering-parsing-time-reduction-logs-22-62-68}\%
when a mail loop occurs and the distribution of log lines is unusual.
\Tableref{Parsing time of optimal and reverse orderings relative to
shuffled ordering table} shows that differences in rule ordering have less
effect on parsing time when parsing log files 22 \& 62--68, because of the
different distribution of log lines in those log files.  A careful
examination of \graphref{Parsing time of optimal and reverse orderings
relative to shuffled ordering graph} shows that, for the first log file
only, optimal and reverse orderings perform identically: this is because
the hits field of each rule is zero for the first log file, so optimal and
reverse orderings produce identical rule orderings.  For the first log
file, shuffled ordering is the most efficient of the three, but that is
accidental and cannot be relied upon.

\showgraph{build/graph-hits}{Log lines recognised per rule}{rule hits graph}

\showgraph{build/graph-optimal-and-reverse-vs-shuffle}{Parsing time of
optimal and reverse orderings relative to shuffled ordering}{Parsing time
of optimal and reverse orderings relative to shuffled ordering graph}

\showtable{build/include-optimal-and-reverse-vs-shuffle}{Parsing time of
optimal and reverse orderings relative to shuffled ordering}{Parsing time
of optimal and reverse orderings relative to shuffled ordering table}

\FloatBarrier{}

\subsection{Comparing Optimal Ordering Against An Oracle}

\label{perfect rule ordering}

Optimal rule ordering, as described in \sectionref{rule ordering for
efficiency}, is the best rule ordering it is possible to achieve without
having an oracle that magically divines which rule should be used to
recognise each log line.  Such an oracle would give perfect performance,
because only one rule would need to be used to recognise each log line.
\parsername{} can save a list showing which rule recognised each log line,
and use that list to simulate an oracle and improve parsing speed the
\textit{second\/} time a log file is parsed.  This does not provide a
practical benefit, but it does provide a means to evaluate the performance
of optimal rule ordering in comparison to an oracle.

\Graphref{Parsing time of oracle and optimal ordering relative to shuffled
ordering graph} shows how the oracle and optimal ordering perform relative
to shuffled ordering; \tableref{Parsing time of oracle and optimal ordering
relative to shuffled ordering table} shows mean and standard deviation.  As
expected, the oracle is more efficient than optimal ordering, but not by
much.  \Graphref{Percentage increase in parsing time when using optimal
ordering instead of oracle graph} shows the percentage increase in parsing
time when using optimal ordering instead of the oracle, with mean and
standard deviation in \tableref{Percentage increase in parsing time when
using optimal ordering instead of oracle table}.

Once again, the difference between the oracle and optimal ordering is at
its lowest when parsing log files resulting from a mail loop (log files 22
\& 62--68), because the mean number of rules tried per log line is lower
(see \graphref{Mean number of rules used per log line}).  The performance
of optimal ordering relative to the oracle is much worse when parsing the
first log file than for the remainder of the log files, because for the
first log file the hits field of every rule is zero, so optimal ordering
does not provide any benefit for that log file; the oracle, in contrast, is
flawless for every log file.

Optimal ordering proves to be quite efficient: \tableref{Percentage
increase in parsing time when using optimal ordering instead of oracle
table} shows that optimal ordering is less than
\input{build/include-perfect-best-vs-optimal-mean} slower than parsing
using an oracle that magically divines the correct rule to use for each log
line.


\showgraph{build/graph-perfect-best-and-optimal-vs-shuffled}{Parsing time
of oracle and optimal ordering relative to shuffled ordering}{Parsing time
of oracle and optimal ordering relative to shuffled ordering graph}

\showtable{build/include-perfect-best-and-optimal-vs-shuffle}{Parsing time
of oracle and optimal ordering relative to shuffled ordering}{Parsing time
of oracle and optimal ordering relative to shuffled ordering table}

\showgraph{build/graph-perfect-best-vs-optimal}{Percentage increase in
parsing time when using optimal ordering instead of oracle}{Percentage
increase in parsing time when using optimal ordering instead of oracle
graph}

\showtable{build/include-perfect-best-vs-optimal-stddev}{Percentage
increase in parsing time when using optimal ordering instead of
oracle}{Percentage increase in parsing time when using optimal ordering
instead of oracle table}

\FloatBarrier{}

\subsection{Scalability As The Ruleset Grows}

\label{scalability as the number of rules rises}

How any architecture scales as the number of rules increases is important,
but it is particularly important for this architecture because it is
anticipated that the typical parser will have a large ruleset.  The full
\parsername{} ruleset has \numberOFrules{} rules, whereas the minimum
ruleset required to parse the \numberOFlogFILES{} log files has
\numberOFrulesMINIMUM{} rules, \numberOFrulesMINIMUMpercentage{} of the
full ruleset.  The full ruleset is larger because \parsername{} is tested
with \numberOFlogFILESall{} log files; testing with more log files
increases the chance of finding bugs in the parser or new complications to
be overcome.  The \numberOFlogFILES{} log files were each parsed 10 times
using the minimum ruleset, and the mean parsing times compared to those
generated using the full ruleset: the percentage parsing time increase when
using the full ruleset instead of the minimal ruleset for optimal,
shuffled, and reverse orderings is shown in \graphref{Percentage parsing
time increase when using the maximum ruleset instead of the minimum
ruleset}, with mean and standard deviation in \tableref{Percentage parsing
time increase when using the maximum ruleset instead of the minimum ruleset
table}.

Clearly the increased number of rules causes a noticeable performance
decrease with reverse ordering, and a lesser decrease with shuffled
ordering, whereas optimal ordering shows scant change.  Log files 22 \&
62--68 show much smaller increases in parsing time than other log files do,
because most of the log lines in those log files are produced by Postfix
components with few rules, so removing unnecessary rules has little effect
on the total number of rules used; \tableref{Number of rules per Postfix
component in the maximum and minimum rulesets} shows the number of rules
per Postfix component for each ruleset.  Once again, for the first log
file, optimal and reverse orderings have identical performance, because the
hits field of every rule starts at zero.

The optimal ordering has a mean increase of just
\input{build/include-full-ruleset-vs-minimum-ruleset-mean} in parsing time
for a \numberOFrulesMAXIMUMpercentage{} increase in the number of rules.
These results show that both the architecture and \parsername{} scale
extremely well as the ruleset increases in size, and that optimally
ordering the rules is an important optimisation contributing to this
scalability.

\showgraph{build/graph-full-ruleset-vs-minimum-ruleset}{Percentage parsing
time increase when using the maximum ruleset instead of the minimum
ruleset}{Percentage parsing time increase when using the maximum ruleset
instead of the minimum ruleset}

\showtable{build/include-full-ruleset-vs-minimum-ruleset}{Percentage
parsing time increase when using the maximum ruleset instead of the minimum
ruleset}{Percentage parsing time increase when using the maximum ruleset
instead of the minimum ruleset table}

\begin{table}[thbp]
    \caption{Number of rules per Postfix component in the maximum and
    minimum rulesets}
    \empty{}\label{Number of rules per Postfix component in the maximum and
    minimum rulesets}
    \centering{}
    \begin{tabular}{lrr}
        \tabletopline{}%
        Postfix component & Maximum ruleset & Minimum ruleset \\
        \tablemiddleline{}%
        \input{build/include-number-of-rules-per-program-minimum-ruleset}
        \tablebottomline{}%
    \end{tabular}
\end{table}

\FloatBarrier{}

\subsection{Caching Compiled Regexes}

\label{Caching compiled regexes}

Before the Perl interpreter attempts to match a regex against a piece of
text, the regex is compiled into an internal representation and optimised
to improve the speed of matching.  This compilation and optimisation takes
CPU time: for most regexes it takes far more CPU time than the actual
matching.  If the interpreter is certain that a regex will not change while
the program is running, it will automatically cache the results of
compiling and optimising the regex for later use.  The results of compiling
a dynamically generated regex can be cached and used in preference to the
original regex, but it is the responsibility of the programmer to do so;
\parsername{} does this with every rule's regex when the rules are loaded
from the database.

\Graphref{Increase in parsing time when not caching compiled regexes graph}
shows the effect that not caching compiled regexes has on parser
performance, with mean and standard deviation in \tableref{Increase in
parsing time when not caching compiled regexes table}.  For typical log
files, the mean increase in parsing time when not caching compiled regexes
is \input{build/include-cached-regexes-vs-discarded-regexes-mean}.  Caching
compiled regexes is probably the single most effective optimisation
possible in \parsername{}, and was quite simple to implement.  As seen
previously, log files 22 \& 62--68 do not suffer such a large increase in
parsing time when the optimisation is disabled; this is because, on
average, fewer regexes are compiled per log line for those log files.  The
increase in parsing time when parsing the first log file is much greater
than for the other log files; again, this is because every rule's hits
field starts at zero, so optimal ordering is less efficient than usual, the
mean number of rules tried for each log line will be higher than usual, and
more regexes will need to be compiled when recognising each log line.

\showgraph{build/graph-cached-regexes-vs-discarded-regexes}{Increase in
parsing time when not caching compiled regexes}{Increase in parsing time
when not caching compiled regexes graph}

\showtable{build/include-cached-regexes-vs-discarded-regexes}{Increase in
parsing time when not caching compiled regexes}{Increase in parsing time
when not caching compiled regexes table}

\FloatBarrier{}

\subsection{Where Is The Time Spent: Recognising Or Processing Log Lines?}

\label{recognising vs processing}

The optimisations described in this chapter have optimised the process of
recognising log lines, but have not optimised actions at all.  Optimisation
efforts have concentrated on recognition of log lines for two reasons:

\begin{enumerate}

    \item Even with the optimisations described in this chapter enabled,
        recognising log lines still dominates the execution time of the
        parser.  \Graphref{Percentage of parsing time spent recognising log
        lines graph} shows the percentage of parsing time spent recognising
        log lines for each of the \numberOFlogFILES{} log files, with mean
        and standard deviation shown in \tableref{Percentage of parsing
        time spent recognising log lines table}; for normal log files,
        \input{build/include-percentage-time-spent-recognising-log-lines-mean}
        of parsing time is spent recognising log lines.  Optimal ordering
        reduces parsing time by
        \input{build/include-optimal-ordering-parsing-time-reduction-other-logs}\%
        relative to shuffled ordering; processing recognised log lines
        occupies
        \input{build/include-percentage-time-spent-processing-log-lines-mean}
        of parsing time, less if any optimisations are disabled, so
        optimising actions could not possibly provide as big a performance
        increase as optimally ordering rules.  Similarly, caching compiled
        regexes provides an
        \input{build/include-cached-regexes-vs-discarded-regexes-mean-reduction}
        reduction in parsing time; not invoking actions at all reduces the
        most optimised parsing time by less than half that.  If processing
        of recognised log lines was optimised to 1\% of its original
        parsing time, it would be only slightly more effective than optimal
        ordering, but it would be vastly harder to implement; optimising
        actions would not reduce parsing time enough to justify the amount
        of effort required.

    \item The process of recognising log lines is not parser-specific
        (excluding evaluation of rule conditions), so the optimisations
        described in this chapter are applicable to all parsers based on
        this architecture.  Actions are parser-specific, so it is unlikely
        that any optimisations made to actions would be portable to other
        parsers.

\end{enumerate}

Individual actions or the framework could and have been optimised, but
plenty of existing literature is available on the topic of optimising
programs, so the subject will not be dealt with here.

\showgraph{build/graph-percentage-time-spent-recognising-log-lines}{Percentage
of parsing time spent recognising log lines}{Percentage of parsing time
spent recognising log lines graph}

\showtable{build/include-percentage-time-spent-recognising-log-lines-table}{Percentage
of parsing time spent recognising log lines}{Percentage of parsing time
spent recognising log lines table}

\FloatBarrier{}

\section{Coverage}

\label{parsing coverage}

The discussion of \parsernames{} coverage of Postfix log files is separated
into two parts: log lines correctly recognised, and mail delivery attempts
correctly understood --- the former is a requirement for the latter to be
achieved.  Correctly understanding and reconstructing every mail delivery
attempt is important so that the information in the database is correct and
complete.  Improving the proportion of log lines correctly recognised is
the less difficult of the two, because it just requires new rules to be
written or existing rules to be extended.  Improving the proportion of
correctly understood and reconstructed mail delivery attempts is more
difficult and intrusive, because it requires adding or changing actions,
and it can be much harder to realise that a deficiency exists and needs to
be addressed.

\subsection{Log Lines Correctly Recognised}

\label{log-lines-covered}

Parsing a log line is a three step process:

\begin{enumerate}

    \squeezeitems{}

    \item Skip the log line if the ruleset does not contain any rules for
        the Postfix component that produced the log line.

    \item Try each rule until a recognising rule is found; if the log line
        is not recognised, issue a warning and move on to the next log
        line.

    \item Invoke the action specified by the recognising rule.

\end{enumerate}

Each Postfix component whose log lines are of interest must have at least
one rule, or its log lines will be silently skipped; in the extreme case of
an empty ruleset the parser would skip every log line.  \parsername{} skips
log lines logged by programs that do not have any rules because there may
be any number of log lines from other programs intermingled in the log
file, and some Postfix components that do not produce any log lines of
interest.  \parsername{} does not parse log lines from non-Postfix
programs, e.g.\ Amavisd-new or SpamAssassin; it could easily be extended to
do so, if a method could be developed to correctly associate such log lines
with existing state table entries.  To correctly recognise all log lines,
there must be a rule to recognise each log line variant produced by each
Postfix component; if a log line is not recognised the parser will issue a
warning, to inform the user that they need to extend their ruleset.  Each
rule's regex should be as specific and precise as possible, to ensure
accurate parsing: a rule with a regex that matches zero or more of any
character will recognise every log line, but not in a meaningful way; most
log lines contain fixed strings, so this is not a problem in practice.

Full coverage of log lines can be achieved without undue effort, yet once
achieved it is hard to maintain.  Maintaining full coverage is hard because
the set of log line variants changes over time, e.g.\ administrators add
restrictions with custom messages, \acronym{DNSBL} messages change, or
major releases of Postfix change log lines (usually by adding more
information).  Warnings are issued for any log lines that are not
recognised; no warnings are issued for unrecognised log lines while parsing
the \numberOFlogFILES{} log files, so it can be safely concluded that zero
false negatives arise.  False positives are harder to quantify, short of
examining each of the 60,721,709 log lines and checking that the correct
rule recognised it.  However, a random sample of 6039 log lines was parsed,
and the results manually verified by inspection to ensure that the correct
rule recognised each log line.  The sample was generated by running the
command: \texttt{perl -n -e \singlequote{}print if (rand 1 <
0.0001)\singlequote{} LOG\_FILES} to randomly extract roughly one log line
in every 10,000 (it actually extracted 0.00994\% instead of 0.01\%).  Each
log line was examined and the correct rule identified from the
\numberOFrules{} rules in the database; the correct rule was then compared
to the rule that recognised the log line when parsing.  The sample results
contained zero false positives, and this check has been automated to ensure
continued accuracy.  Based on these results, and how precise each rule's
regex is, the author is confident that zero false positives occur when
parsing the \numberOFlogFILES{} log files.  On initial appearances,
exercising only 36 rules from a total of \numberOFrules{} when parsing 6039
log lines seems low, but after examining \graphref{rule hits graph} it
becomes apparent that such a low number of rules is to be expected.  The
reader should also bear in mind that even when parsing all
\numberOFlogFILES{} log files, only \numberOFrulesMINIMUM{} rules are used,
because many of the rules recognise log lines that only appear in other log
files.

\subsection{Mail Delivery Attempts Correctly Understood And Reconstructed}

\label{mails-covered}

The proportion of mail delivery attempts that are correctly understood and
reconstructed is much more difficult to determine accurately than the
proportion of log lines that are correctly recognised.  The parser can dump
its state tables in a human readable form; examining those tables with
reference to the log files is the best way to detect mails that were not
handled properly (many of the complications discussed in
\sectionref{complications} were detected in this way).  \parsername{}
issues warnings when it detects any errors or discrepancies, e.g.\ when a
queueid is reused but the previous mail remains in the state tables, when a
queueid or \acronym{pid} is not found in the state tables, or when an entry
in the state tables does not include sufficient data to satisfy the
database schema.  The parser should produce few or no warnings during
parsing, and when finished parsing the state tables should only contain
entries for mails that have log lines in subsequent log files.  There will
often be warnings about a missing queueid or \acronym{pid} when parsing the
first few thousand log lines, because the earlier log lines for those
connections or mails are in a previous log file; loading saved state tables
from the previous log file will solve this problem.

The data used in this chapter is generated by parsing \numberOFlogFILES{}
log files.  5 warnings are produced, but because \parsername{} errs on the
side of producing more warnings rather than fewer, those 5 warnings
represent 3 instances of 1 problem: 3 connections that started before the
first log file, so their initial log lines are missing, leading to warnings
when their remaining log lines are parsed.  None of the warnings are false
positives.

The state tables will contain entries for mails not yet delivered when the
parser finishes execution.  Ideally, that is all they will contain, though
they may also contain mails whose initial log lines are not contained in
the log files.  Any other entries in the state tables are evidence of
either a failure in parsing, or an aberration in the log files.  After
parsing the \numberOFlogFILES{} log files, the state tables contain 18
entries:

\begin{itemize}

    \squeezeitems{}

    \item 1 connection that started only seconds before the log files
        ended and had not yet been fully transferred from client to server.

    \item 1 mail that had been accepted only seconds before the log files
        ended and had not yet been delivered.

    \item 9 mails whose initial log lines were not present in the log
        files.  These mails did not produce warnings because they resemble
        child mails waiting to be tracked with a parent; see
        \sectionref{Re-injected mails} for details.

    \item 7 mails that had yet to be delivered because of repeated
        failures.

\end{itemize}

All of the mails remaining in the state tables have valid reasons for being
present, so it can be concluded that zero false negatives occur when
parsing the \numberOFlogFILES{} log files.  Once again, determining the
false positive rate is much harder, because manually checking the results
of parsing \numberOFconnectionsINlogFILES{} connections and mails accepted,
rejected, bounced, or delivered is infeasible.  Considerable evidence
exists that the false positive rate is extremely low, if not zero:

\begin{itemize}

    \item \parsername{} performs many checks to detect known problems
        occurring, e.g.\ if a mail is missing required data, and no
        warnings are produced during the test runs other than the five
        described above.

    \item Queueids and \glspl{pid} naturally identify log lines belonging
        to one mail or connection respectively; it is extremely unlikely
        that a log line would be associated with the wrong connection.

    \item When dealing with the complications described in
        \sectionref{complications}, the solutions are as specific and
        restrictive as possible, with the goal of minimising the number of
        false positives.  In addition, the solution to the complication
        described in \sectionref{out of order log lines} imposes conditions
        that each reconstructed mail must comply with to be acceptable.

    \item Every effort has been made to make \parsername{} as precise,
        demanding, and particular as possible.

\end{itemize}

%\verb!perl -Mstrict -Mwarnings -MList::Util=shuffle -e! \newline{}
%\verb!     '@ARGV = [shuffle(@ARGV)]->[0];!             \newline{}
%\verb!      while (<>) {!                               \newline{}
%\verb!          if (rand 1 < 0.0001) {!                 \newline{}
%\verb!              foreach my $i (1 .!.  6000) {!        \newline{}
%\verb!                  print scalar <>;!               \newline{}
%\verb!              }!                                  \newline{}
%\verb!              exit;!                              \newline{}
%\verb!          }!                                      \newline{}
%\verb!      }' LOG_FILES!

Verifying by inspection that the parser correctly processes all
\numberOFconnectionsINlogFILES{} mail delivery attempts in the
\numberOFlogFILES{} log files is infeasible, but verifying the parsing of a
sample from those log lines is a tractable albeit extremely time consuming
task.  A sample of log lines was obtained by randomly selecting a log file,
and then randomly selecting a block of 6000 contiguous log lines from it
(0.00988\% of the total number of log lines).  It is important that the log
lines are contiguous, so that all log lines are present for as many of the
mail delivery attempts contained in the block as possible.  This log
segment was parsed with all debugging options enabled, resulting in 167,448
lines of output.\footnote{A mean of 27.908 lines of output per log line;
each connection has 30 debugging lines, plus 21 debugging lines per result.
Connections which have been cloned will have the cloned connection in their
debugging output, plus another 33 debugging lines.  Those numbers are
approximate, and may vary $\pm{}$ 2.  An approximate linear relationship
between the number of log lines and debugging lines is: $33(connections) +
30(accepted~~mails) + 21(results)$.} All 167,448 lines were examined in
conjunction with the log file segment and a dump of the resulting database,
verifying that for each of the log lines \parsername{} recognised it with
the correct rule and invoked the correct action, which in turn correctly
processed the log line and saved the correct data to be inserted into the
database.  The log file segment produced 4 warnings, 10 mails correctly
remaining in the state tables, 1625 mail delivery attempts correctly
entered in the database, zero false positives, and zero false negatives.

Given the evidence detailed above, the author is confident that the false
positive rate when reconstructing a mail delivery attempt from the
\numberOFlogFILES{} log files is exceedingly low, if not zero.

\section{Summary}

This chapter evaluated \parsername{} on two criteria: efficiency, and
coverage of Postfix log files.  The former began by describing the mail
server the log files were taken from, the computer used to generate the
statistics in this chapter, and the characteristics of the
\numberOFlogFILES{} log files used to generate statistics and test
coverage, including why performance is better on the larger log files.  The
framework optimises the order in which rules are used when trying to
recognise each log line, and the effect that optimisation has on parsing
time is explored; this is followed by comparing optimal ordering with an
oracle.  How \parsername{} scales as the size of the ruleset increases is
addressed, followed by a description and analysis of the simplest and most
effective of the optimisations, caching compiled regexes, and the
efficiency evaluation concludes with an examination of where parsing time
is spent: recognising log lines or processing them?

Coverage of Postfix log files is divided into two topics in this chapter:
log lines correctly recognised, and mail delivery attempts correctly
understood and reconstructed.  The former is initially more important,
because the parser must correctly recognise every log line if it is to be
complete, but subsequently the latter takes precedence because correctly
reconstructing the journey a mail delivery attempt takes through Postfix is
the aim of the parser.  Increasing the proportion of log lines correctly
recognised is relatively simple and non-intrusive: adding new rules or
modifying existing rules is very easy because of the separation of rules,
actions, and framework in both the architecture and \parsername{}.
Improving the understanding and reconstruction of mail delivery attempts is
harder, because Postfix's behaviour must be analysed and figured out, and
support for the newly understood behaviour integrated into the actions
without breaking the existing parsing.  Detecting a deficiency in the
parser's understanding of mail delivery attempts requires careful study of
any warnings produced and the entries remaining in the state tables.
Rectifying a flaw in the parser requires a deep understanding of Postfix's
log files, and a working knowledge of the framework, actions, and rules;
investigative work will be needed to determine the cause of the deficiency,
followed by further examination of the log files to aid in developing a
solution, and finally implementation, integration, and testing of the
solution.

This chapter shows that it is possible to balance the conflicting goals of
efficient and accurate parsing, and that one does not have to be sacrificed
to achieve the other.
