\chapter{Results And Evaluation}

\label{Results}

\renewcommand{\figurename}{Graph}

XXX NEED AN INTRODUCTION\@.

XXX USE THE DATA COLLECTED ABOUT NUMBER OF RULES TRIED\@.  MAYBE INCLUDE IN
ORDERINGS SECTION\@?  MIX WITH RECOGNISING VS RECOGNISING + ACTION, AND
KEEP COUNTERS FOR EACH PROGRAM TOO --- MAYBE SOMETHING USEFUL WILL COME
FROM IT\@.  COMPARE NUMBER OF RULES TRIED FOR DIFFERENT RULE ORDERINGS\@.

XXX SHOULD I USE $\backslash{}$clearpage{} OR SOMETHING TO AFFECT FLOAT
PLACEMENT\@?  GRAPHS AND TABLES TEND TO MOVE QUITE FAR IN SOME OF THE
SUBSECTIONS, THOUGH MAKING THE TEXT LONGER MIGHT HELP TOO\@.  IDEALLY I
WANT TO HAVE TEXT, THEN ALL GRAPHS AND TABLES, THEN THE NEXT SECTION\@.

\newpage{} % XXX VARIOREF PROBLEMS

\section{Parser Efficiency}

\label{parser efficiency}

Parsing efficiency is an obvious concern when the parser routinely needs to
parse large log files.  The server that generated the log files used in
testing this parser accepts approximately 10,000 mails for 700 users per
day; \graphref{Mails received per day} and \tableref{Number of mails
received per day: statistics} show that, as expected, far more mails are
received on weekdays than at weekends.  The mail server in question is a
production mail server handling mail for a university department; the
benefit of using this server is that its log files exhibit the
idiosyncrasies and peculiarities a mail server in the wild must deal with,
but the downside is that significantly altering the configuration to
accommodate this project is not an option.  Median log file size is 50MB,
containing 285,000 log lines; large scale mail servers would have much
larger log files.  Note that \graphref{Mails received per day} and
\tableref{Number of mails received per day: statistics} show the number of
mails received by \acronym{SMTP} only, and the mail loops noticeable in
later graphs do not contribute to these figures.

\showgraph{build/graph-mails-received}{Number of mails received via SMTP
per day}{Mails received per day}

\showtable{build/include-mails-received-table}{Number of mails received via
SMTP per day}{Number of mails received per day: statistics}

\begin{table}[htbp]
    \caption{Details of the computer used to generate statistics}
    \empty{}\label{Details of the computer used to generate statistics}
    \begin{tabular}[]{ll}
        \tabletopline{}%
        Component  & Component in use                                   \\
        \tablemiddleline{}%
        CPU         & One dual core 2.40GHz Intel\textregistered{}
                        Core\texttrademark{}2 CPU,                      \\
                    & with 32KB L1 cache and 4MB L2 cache.              \\
        RAM         & 2GB 667 MHz DDR RAM\@.                            \\
        Hard disk   & One Seagate Barracuda 7200 RPM 250GB SATA disk.   \\
        \tablebottomline{}%
    \end{tabular}
\end{table}

When generating the timing data used in this section, \numberOFlogFILES{}
log files (totaling 10.08 GB, \numberOFlogLINEShuman{} log lines) were each
parsed 10 times, and the times from the 10 runs averaged.  The computer
used for test runs was a Dell Optiplex 745, shown in \tableref{Details of
the computer used to generate statistics}; it was dedicated to the task of
gathering statistics from test runs, and was not used for any other purpose
while test runs were ongoing.  Saving results to the database was disabled
for the test runs, because that dominates the run time of the parser, and
the tests are aimed at measuring the speed of \parsername{} rather than the
speed of the database and the disks the database is stored on.  Parsing all
\numberOFlogFILES{} log files in one run without saving results to the
database took \input{build/include-full-run-duration}, mean throughput was
\input{build/include-full-run-throughput}; median throughput when parsing
files separately was \input{build/include-median-throughput-MB}
(\input{build/include-median-throughput-log-lines}) parsed per minute.  In
contrast, when saving results to the database, parsing all
\numberOFlogFILES{} log files took
\input{build/include-insert-results-duration}, with mean throughput of
\input{build/include-insert-results-throughput}.  Parsing makes up only
\input{build/include-skip-inserting-as-percentage-of-inserting} of the
execution time when saving results to the database, so a 50\% improvement
in the speed of parsing would result in only a
\input{build/include-skip-inserting-with-50-percent-improvement--as-percentage-of-inserting}
improvement in speed overall.

\subsection{Architecture Scalability: Input Size}

An important property of a parser is how parsing time scales relative to
input size: does it scale linearly, polynomially, or exponentially?
\Graphref{parsing time vs file size vs number of log lines graph} shows the
parsing time in seconds, file size in MB, and number of log lines in tens
of thousands, for each of the \numberOFlogFILES{} log files.  The three
lines run roughly in parallel, giving the impression that the algorithm
scales linearly with input size.  This impression is borne out by
\graphref{parsing time vs file size vs number of log lines factor}, which
plots both the ratio of file size vs parsing time, and the ratio of number
of log lines vs parsing time (higher is better in both cases);
\tableref{parsing time vs file size vs number of log lines factor table}
shows the same ratios for different groups of log files.  The ratios are
quite tightly banded, showing that the algorithm scales linearly; the
ratios increase (i.e.\ improve) for log files 22 and 62--68, despite their
larger than average size.  Both groups of log files are much larger than
usual due to a mail loop caused by a user who set up mail forwarding
incorrectly, resulting in a very different distribution of log lines:
normally most log lines are generated by mail delivery attempts from other
hosts, but when the mail loops occurred most of the log lines resulted from
failed delivery of mail generated on the server itself.  The Postfix
components that generated most of the log lines during the mail loop have
fewer associated rules than the Postfix components whose log lines normally
make up the bulk of each log file, so the average number of rules tried per
log line reduces and so does the average parsing time per log line.
\Graphref{Number of rules per Postfix component} shows the number of rules
per Postfix component, \graphref{Average number of rules tried per log
line} shows the drop in the average number of rules tried per log line for
log files containing a mail loop, and \graphref{Average number of rules
tried per log line for each Postfix component} shows the average number of
rules tried per log line for each Postfix component.

\showtable{build/include-file-size-and-number-of-log-lines-vs-parsing-time}{Ratio
of file size and number of log lines to parsing time}{parsing time vs file
size vs number of log lines factor table}

\showgraph{build/graph-input-size-vs-parsing-time}{Parsing time, file size,
and number of log lines for \numberOFlogFILES{} log files}{parsing time vs
file size vs number of log lines graph}

\showgraph{build/graph-input-size-vs-parsing-time-ratio}{Ratio of file size
and number of log lines to parsing time}{parsing time vs file size vs
number of log lines factor}

\showgraph{build/graph-average-number-of-rules-tried-per-log-line}{Average
number of rules tried per log line}{Average number of rules tried per log
line}

\showgraph{build/graph-average-number-of-rules-tried-per-program}{Average
number of rules tried per log line for each Postfix component}{Average
number of rules tried per log line for each Postfix component}

\begin{table}[htbp]
    \caption{Number of rules per Postfix component}
    \empty{}\label{Number of rules per Postfix component}
    \centering{}
    \begin{tabular}{lr}
        \tabletopline{}%
        Postfix component & Number of rules \\
        \tablemiddleline{}%
        \input{build/include-number-of-rules-per-program}
        \tablebottomline{}%
    \end{tabular}
\end{table}

\FloatBarrier{}

\subsection{Rule Ordering For Efficiency}

\label{rule ordering for efficiency}

\parsername{} has \numberOFrules{} rules: the top 10\% recognise
\input{build/include-top-ten-hits}\% of the log lines, with the remaining
log lines split across the other 90\% of the rules (as shown in
\graphref{rule hits graph}).  Assuming that the distribution of log lines
is reasonably consistent over time, \parsernames{} efficiency should
benefit from trying rules that recognise log lines more frequently before
those rules that recognise log lines less frequently.  To test this
hypothesis, three full test runs were performed with different rule
orderings:

\begin{eqlist}

    \item [Optimal]  The most optimal order, according to the hypothesis:
        rules that recognise log lines most often will be tried first.

    \item [Shuffle] This ordering is intended to represent a randomly
        ordered rule set.  The rules will be shuffled once before use and
        will retain that ordering until the parser exits.  Note that the
        ordering will change every time the parser is executed, so 10
        different rule orderings will be generated for each log file in the
        test run.

    \item [Reverse] Hypothetically the worst order: the rules that
        recognise log lines most frequently will be tried last.

\end{eqlist}

\Graphref{Parsing time relative to shuffled ordering graph} shows the
parsing times of optimal and reverse orderings relative to shuffled
ordering; the mean relative parsing times for different groupings of log
files are given in \tableref{Parsing time relative to shuffled ordering
table}.  This optimisation provides a mean reduction in parsing time of
\input{build/include-optimal-ordering-parsing-time-reduction-other-logs}\%
with normal log files,
\input{build/include-optimal-ordering-parsing-time-reduction-logs-22-62-68}\%
when a mail loop occurs and the distribution of log lines is unusual.
Optimal rule ordering has other benefits, described in
\sectionref{scalability as the number of rules rises}.  Differences in rule
ordering have less effect on parsing time when parsing log files 22 and
62--68, due to the different distribution of log lines in those log files.

\showgraph{build/graph-hits}{Log lines recognised per rule}{rule hits graph}

\showgraph{build/graph-optimal-and-reverse-vs-shuffle}{Parsing time
relative to shuffled ordering}{Parsing time relative to shuffled ordering
graph}

\showtable{build/include-optimal-and-reverse-vs-shuffle}{Parsing time
relative to shuffled ordering}{Parsing time relative to shuffled ordering
table}



\subsection{Perfect Rule Ordering}

\label{perfect rule ordering}

XXX WRITE ABOUT PERFECT RULE ORDERING\@; DUNNO WHETHER TO PUT IT IN WITH
RULE ORDERING FOR EFFICIENCY, OR IN ITS OWN SECTION\@.

XXX ADD A TABLE SHOWING PERFECT WORST RELATIVE TO PERFECT BEST\@.

\showgraph{build/graph-perfect-best-and-perfect-worst-and-optimal-and-reverse-vs-shuffled}{Parsing
time including perfect best and worst relative to shuffled
ordering}{Parsing time relative to shuffled ordering including perfect best
and worst graph}

\showtable{build/include-perfect-best-and-optimal-and-reverse-and-perfect-worst-vs-shuffle}{Parsing
time including perfect best and worst relative to shuffled
ordering}{Parsing time including perfect best and worst relative to
shuffled ordering table}

% XXX \FloatBarrier{} MIGHT BE USEFUL TO CONTROL WHERE FLOATS ARE PLACED.

\subsection{Where Is The Time Spent: Recognising Or Processing Log Lines?}

\label{recognising vs processing}

XXX EXAMINE THE TIME SPENT RECOGNISING LOG LINES VS THE TIME SPENT
PROCESSING THEM\@.

\subsection{Scalability When The Number Of Rules Rises}

\label{scalability as the number of rules rises}

How any architecture scales as the number of rules increases is important,
but it is particularly important in this architecture because it is
expected that the typical parser will have a large number of rules.  There
are \numberOFrules{} rules in the full \parsername{} ruleset, whereas the minimum
number of rules required to parse the \numberOFlogFILES{} log files used
when generating the results in this thesis is \numberOFrulesMINIMUM{},
\numberOFrulesMINIMUMpercentage{} of the full ruleset.  The full ruleset is
larger because \parsername{} is tested with \numberOFlogFILESall{} log
files, to improve its parsing and ensure it correctly parses logs generated
by later Postfix versions.  A second set of test runs was performed using
the minimum ruleset, and the parsing times compared to those generated
using the full ruleset: the percentage parsing time increase when using the
full ruleset instead of the minimal ruleset for optimal, shuffled and
reverse orderings is shown in \graphref{Percentage parsing time increase of
maximum ruleset over minimum ruleset}.

\showgraph{build/graph-full-ruleset-vs-minimum-ruleset}{Percentage parsing
time increase of maximum ruleset over minimum ruleset}{Percentage parsing
time increase of maximum ruleset over minimum ruleset}

Clearly the increased number of rules has a noticeable performance impact
with reverse ordering, and a lesser impact with shuffled ordering.  The
optimal ordering shows a mean increase of
\input{build/include-full-ruleset-vs-minimum-ruleset} in parsing time for a
\numberOFrulesMAXIMUMpercentage{} increase in the number of rules.
XXXXXXXXXXXX IMPROVE THIS EXPLANATION\@.  Log files 22 and 62--68 show much
smaller increases for shuffled and reversed ordering than other log files
do, because the majority of log lines in those log files are parsed by
Postfix components with a small number of parsing rules, so removing
unnecessary rules has little effect on the total number of rules used.
These results show that the architecture scales very well as the number of
rules increases, and that optimally sorting the rules is an important
optimisation contributing to this scalability.

\subsection{Caching Compiled Regexes}

\label{Caching compiled regexes}

Before the Perl interpreter attempts to match a regex against a piece of
text, the regex is compiled into an internal representation and optimised
to improve the speed of matching.  This compilation and optimisation takes
CPU time: in many cases it takes far more CPU time than the actual
matching.  If the interpreter is certain that a regex will not change, it
will automatically cache the compilation results for later use.   The
results of compiling a dynamically generated regex can be cached and used
in preference to the original regex, but it is the responsibility of the
programmer to do this.  \parsername{} loads the rules it uses from a
database, so it compiles each rule's regex and caches the result to reduce
parsing time.

\Graphref{Increase in parsing time when not caching compiled regexes graph}
shows the impact that not caching compiled regexes has on parser
performance: on typical log files, the parsing time when not caching
compiled regexes is 400--600\% of the parsing time when caching.  Caching
compiled regexes is probably the single most effective optimisation
possible in \parsername{}, and was quite simple to implement.

\showgraph{build/graph-cached-regexes-vs-discarded-regexes}{Increase in
parsing time when not caching compiled regexes}{Increase in parsing time
when not caching compiled regexes graph}

XXX UPDATE THIS\@.  Two large dips can be seen in \graphref{Increase in
parsing time when not caching compiled regexes graph} at log files 22 and
62--68, corresponding to the spikes in log file size in \graphref{parsing
time vs file size vs number of log lines graph}.  The distribution of log
lines across rules when there is a mail loop is much different to the norm,
and the average number of rules consulted per log line is much lower: this
results in far fewer regex compilations per line when there is a mail loop,
and a corresponding decrease in the average parsing time for a single log
line.  The outcome is that caching compiled regexes is proportionally less
important when the log file contents were created by a mail loop.  The
increases in parsing time when not caching compiled regexes for different
groups of log files are summarised in \tableref{Increase in parsing time
when not caching compiled regexes table}.

\showtable{build/include-cached-regexes-vs-discarded-regexes}{Increase in
parsing time when not caching compiled regexes}{Increase in parsing time
when not caching compiled regexes table}


\subsection{Summary}

XXX REWRITE WHEN THIS CHAPTER IS FINISHED\@.

This section began with parser scalability, showing the linear relationship
between parsing time and input size.  Demonstrates the effect of rule
ordering on parsing time, and the unexpected consequences of specific
inputs.  The necessity of caching compiled regexes is attested to by the
third group of graphs, where the difference between caching and not caching
is staggering.  The penultimate section contains a breakdown of the rule
hits accumulated during a single test run of the parser.  Miscellaneous
graphs expected to be useful are collected in the final section.

\section{Coverage}

XXX I THINK THIS SECTION NEEDS SUBSTANTIAL WORK, IF NOT A RE-WRITE\@; START
WITH THE PAPER'S CONTENT\@.

\label{parsing coverage}

The discussion of the parser's coverage of Postfix log files is separated
into two parts: log lines covered and mails covered.  The first is
important because the parser should handle all (relevant) log lines it is
given; the second is equally important because the parser must properly
deal with every mail if it is to be useful.  Improving the former is
less intrusive, as it just requires new rules to be written; improving the
latter is much more intrusive as it requires changes to the parser
algorithm, and it can also be much harder to notice a deficiency.

\subsection{Log Lines Covered}

\label{log-lines-covered}

Parsing a log line is a three stage process:

\begin{enumerate}

    \item Check if there are any rules for the Postfix component that
        produced the log line; if not then skip the log line.

    \item Try each rule until a recognising rule is found; if the log line
        is not recognised, issue a warning and move to the next log line.

    \item Execute the action specified by the rule.

\end{enumerate}

Full coverage of log lines requires the following:

\begin{enumerate}

    \item Each Postfix component whose log lines are of interest must have
        at least one rule or its log lines will be silently skipped; in the
        extreme case of zero rules the parser would happily skip every log
        line.  There may be any number of log lines from other programs
        intermingled in the log file, and there are some Postfix programs
        that do not produce any log lines of interest.

    \item There must be a rule to recognise each different log line
        produced by each program; if a log line is not successfully
        recognised the parser will issue a warning.  Rules should be as
        specific and tightly bound as possible to ensure accurate
        parsing:\footnote{A rule with a regex that matches zero or more of
        any character will successfully recognise every log line, but not
        in a meaningful way.} most log lines contain fixed strings and have
        a rigid pattern, so this is not a problem.

    \item The appropriate action to take --- discussed in
        \sectionref{mails-covered}.

\end{enumerate}

Full coverage of log lines is easy to achieve yet hard to maintain.  It is
easy to achieve full coverage for a limited set of log files (at the time
of writing the parser is tested with \numberOFrules{} rules, fully parsing
\numberOFlogFILESall{} contiguous log files from Postfix 2.2 through to
Postfix 2.5), and new rules are easy to add.  Maintaining full coverage is
hard because other servers have different restrictions with custom
messages, \acronym{DNSBL} messages change over time, major releases of
Postfix change warning messages (usually adding more information), etc.,\
so over time the log lines drift and change.  \Graphref{rule hits graph}
shows the number of hits for each rule over all \numberOFlogFILES{} log
files.  The number of hits per rule is quite unevenly spread, resembling a
Power Law distribution --- it is obvious that a small number of rules
recognise the vast majority of the log lines, and more than half the rules
recognise fewer than 100 log lines.

Warnings are issued for any log lines that are not parsed; no warnings are
issued for unparsed log lines while testing with the \numberOFlogFILES{}
test log files, so it can be safely concluded that there are zero false
negatives.  False positives are harder to quantify: short of examining each
of the 60,721,709 log lines and determining which regex parsed it, there
is no way to be sure that every line was parsed by the correct regex,
making it impossible to quantify the false positive rate; however a random
sample of 6,039 log lines was parsed and the results checked manually to
ensure that the correct regex parsed each log line.\footnote{Each log
line was examined and the correct regex identified from the
\numberOFrules{} rules in the database; the correct regex was then
compared to the regex that was used by the parser.}  The sample was
generated by running the following command:

\verb!    perl -e 'print if (rand 1 < 0.0001)' -n LOG_FILES!

\noindent{}to randomly extract roughly one line in every 10,000.  Although
on initial appearances exercising only 36 rules (from a total of
\numberOFrules{}) when parsing 6039 log lines seems quite low, after
examining \graphref{rule hits graph} it becomes apparent that such
a low hit rate is to be expected; the reader should also bear in mind that
even when parsing all \numberOFlogFILES{} log files not all the rules are
exercised (some of the rules are for parsing log lines that only appear in
other log files).

\subsection{Mails Covered}

\label{mails-covered}

Coverage of mails is much more difficult to determine accurately than
coverage of log lines.  The parser can dump its state tables in a human
readable form; examining these tables with reference to the log files is
the best way to detect mails that were not handled properly (many of the
complications discussed in \sectionref{complications} were detected in this
way).  The parser issues warnings when it detects any errors, some of which
may alert the user to a problem, e.g.\ when a queueid is reused before the
previous mail is fully dealt with, when a queueid or \acronym{pid} is not
found in the state tables,\footnote{There will often be warnings about a
missing queueid or \acronym{pid} in the first few hundred or thousand log
lines because the earlier log lines for those connections or mails are in
the previous log file; loading the saved state from the previous log file
will solve this problem.} or when there are problems tracking a child mail
(see \sectionref{tracking re-injected mail}).  There should be few or no
warnings when parsing, and when finished parsing the state table should
only contain entries for mails that had yet to be delivered when the log
files ended, or were accepted before the log files began.

At the time of writing the parser is being tested with \numberOFlogFILES{}
log files.  There are 5 warnings produced, but because the parser errs on
the side of producing more warnings rather than fewer, those 5 warnings
represent 3 instances of 1 problem: 3 connections started before the first
log file, so their initial log lines are missing, leading to warnings when
their remaining log lines are parsed.

The state tables contain entries for mails not yet delivered when the
parser finishes execution.  Ideally all they should contain are mails that
are awaiting delivery after the period covered by the log files, though
they may also contain mails whose initial entries are not contained in the
log files.  Any other entries are evidence of a failure in parsing or an
aberration in the log files.  After parsing the \numberOFlogFILES{} test
log files the state tables contain 18 entries, breaking down into:

\begin{itemize}

    \item 1 connection that started only seconds before the log files
        ended and had not yet been fully transferred from client to server.

    \item 1 mail that had been accepted only seconds before the log files
        ended and had not yet been delivered.

    \item 9 mails whose initial log lines were not present in the log
        files.

    \item 7 mails that had yet to be delivered due to repeated failures.

\end{itemize}

There are no mails in the state tables which should not be present, thus it
can be concluded that there are zero false negatives.  Once again,
determining the false positive rate is much harder, as manually checking
the results of parsing 13,850,793 connections and mails accepted, rejected,
bounced or delivered is infeasible.  There is considerable circumstantial
evidence that the false positive rate is quite low:

\begin{itemize}

    \item The parser is quite verbose when complaining about known problems
        (e.g.\ if a mail is tracked twice as described in
        \sectionref{tracking re-injected mail}), and no such warnings are
        produced during the test runs.

    \item Queueids and \glspl{pid} naturally group together log lines
        belonging to one mail or connection respectively; it is extremely
        unlikely that a log line would be associated with the wrong
        connection.

    \item When dealing with the complications described in
        \sectionref{complications} the solutions are as specific and
        restrictive as possible, with the goal of minimising the number of
        false positives.  In addition the solution to the \textit{Out of
        order log files\/} complication described in \sectionref{out of
        order log lines} imposes conditions that each reassembled mail must
        comply with to be acceptable.

    \item Every effort has been made while developing to make the parser as
        precise, demanding, and particular as possible.

\end{itemize}

Whereas verifying by inspection that the parser correctly deals with all
60,721,709 log lines in the test log files is infeasible, verifying a
subset of those log files is a tractable, if extremely time consuming,
task.  A sample of log lines was obtained by randomly selecting a log file:

\verb!    perl -Mstrict -Mwarnings -MList::Util=shuffle \!\newline{}
\verb!            -e 'print [shuffle(@ARGV)]->[0];'!

The first 6000 log lines of this log file (roughly 0.01\% of the total
number of log lines used in testing) was extracted:

\verb!    sed -n -e '1,6000p' logfile > test-log-segment!

It is important that the log lines used are contiguous so that all log
entries are present for as many of the connections as possible.  This log
segment was parsed with all debugging options enabled, resulting in 167,448
lines of output.\footnote{A mean of 27.908 lines of output per line of
input; each connection has 30 debugging lines, plus 21 debugging lines per
result.  Connections which have been cloned will have the cloned connection
in their debugging output, plus another 33 debugging lines.  Those numbers
are approximate, and may vary $\pm{}$ 2.  There is a linear relationship
between the number of log lines and debugging lines: $33(connections) +
30(accepted~~mails) + 21(results)$.  This formula is an approximation only,
and has not been rigorously verified.}  All 167,448 lines were examined in
conjunction with the input log file and a dump of the resulting database,
verifying that for each of the log lines the parser used the correct rule
and executed the correct action, which in turn produced the correct result
and inserted the correct data in the database.  The log file segment
produced 4 warnings, 10 mails remaining in the state tables, and 1625
connections correctly entered in the database.

Given the circumstantial and experimental evidence detailed above, the
author is confident that the false positive rate when reconstructing a mail
is exceedingly low, if not approaching zero.

\section{Summary}

XXX EXTEND TO SUMMARISE PARSER EFFICIENCY TOO\@.

XXX REWRITE COVERAGE SUMMARY IF NECESSARY\@.

Parser coverage is divided into two topics in this section: log lines
covered and mails covered.  The former is initially more important, as the
parser must successfully parse every line if it is to be complete, but
subsequently the latter takes precedence because reproducing the path a
mail takes through Postfix is the aim of the parser.  Increasing the
percentage of log lines parsed is relatively simple and non-intrusive:
adding new rules or modifying existing rules is simplified by the
separation of rules, actions, and framework.  Improving the logical
coverage is harder, as the actions taken by Postfix must be reconstructed
by the author, and the new sequence of actions integrated into the existing
model without breaking the existing parsing.  Detecting a deficiency in the
parsing algorithm is also significantly harder than detecting unparsed log
lines, as the parser will warn about any unparsed line, whereas discovering
a flaw in the parser requires understanding of the warnings produced and
the mails remaining in the state table.  Rectifying a flaw in the parser
requires an understanding of both the parser and Postfix's log files, and
investigative work to determine the cause of the deficiency, followed by
further examination of the log files in developing a solution.

