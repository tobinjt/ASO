% $Id$
\documentclass[a4paper,12pt,draft]{article}

% Better typesetting of URLs.
\usepackage{url}
% Include images
\usepackage[final]{graphicx}

\begin{document}

\title{Parsing Postfix log files}
\author{John Tobin \\ School of Computer Science and Statistics \\ 
Trinity College \\ Dublin 2 \\ Ireland \\ tobinjt@cs.tcd.ie}
\date{}
\maketitle

\begin{abstract}

    Parsing Postfix logs is much more difficult than it first appears, but
    it is possible.  This paper describes the process required, documenting
    the parsing algorithm and rules, and explaining the difficulties
    encountered, with reference to an implementation which stores data
    gathered from the logs in an SQL database for later processing.

\end{abstract}

XXX WHAT IS THE CONCLUSION??? XXX

\newpage
\tableofcontents

\section{Introduction}

Most mail server administrators will have performed some basic processing
of Postfix logs at one time or another, whether it was to debug a problem,
explain to a user why their mail is being rejected, or to check whether
their new anti-spam measures are working.  The more adventurous will have
generated some statistics to show how many hits each of their anti-spam
measures has gotten in the last week, and possibly even generated some
graphs to clearly illustrate the point to management or complaining
users.\footnote{This was the author's first real foray into processing
Postfix logs.}  Very few will have performed in-depth parsing and analysis
of their logs, where the parsing must correlate the log lines
per-connection or per-queueid, rather than processing lines independently.
One of the barriers to this type of processing is the unstructured nature
of Postfix's logs, where each logging line was added on an ad hoc basis as
a requirement was discovered or new functionality was added.  Further
complication arises as a result of the facility to have rejection messages
defined by the administrator, and every Real-time Black List returns a
different explanatory message.  This paper documents the difficult process
of parsing Postfix logs, and presents a program which parses logs and
places the resulting data into a database for further processing by other
applications.


\section{Background}

\subsection{Postfix background}

Postfix is a highly configurable, high performance, secure and scalable
Mail Transport Agent.  It features extensive anti-spam restrictions,
allowing a mail administrator to deploy those restrictions which they judge
suitable for their needs, rather than a fixed set chosen by Postfix's
author.  These restrictions can be selectively applied, combined and
bypassed on a per-client, per-recipient or per-sender basis, allowing
varying levels of defense and or permissiveness.  Postfix leverages simple
lookup tables to support arbitrarily complicated user-defined sequences of
restrictions and exceptions, with the ultimate in flexibility being the
facility to consult an external process which can implement whatever logic
is required: some users can be restricted to sending mail on the third
Tuesday after pay day only, if that is of any use.\footnote{This example
may actually be useful in a payroll system.  More commonly encountered
scenarios are restricting posting to large mailing lists (e.g. sending
weekly offers to customers) to out of office hours, checking SPF records
(see http://www.openspf.org/ or
http://en.wikipedia.org/wiki/Sender\_Policy\_Framework for details), or
rate limiting clients.}  Administrators can also supply their own rejection
messages, to make it clear to senders why exactly their mail was rejected.
Unfortunately this flexibility has a cost: complexity in the logs
generated.  While it is easy to use \texttt{grep(1)} to determine the fate
of an individual email, following the journey an email takes through
Postfix can be quite difficult.  The logs tend to follow a 90\%-10\%
pattern: 90\% of the time the journey is simple, but the other 10\% of the
time requires 90\% of the code.\footnote{These numbers don't have a solid
scientific basis, they're based on gut feeling from writing and debugging
the software.}

\subsection{Paper background}

This paper and the program it describes are part of a larger project to
optimise a server's Postfix restrictions, generate statistics and graphs,
and provide a platform on which new restrictions can be trialled and
evaluated to see if they are worth using in the fight against spam.  The
program parses Postfix logs and populates a database with the data gleaned
from those logs, providing a consistent and simple view of the logs which
future tools can utilise.  The program should be reasonably easily
extensible, so if logging to a database doesn't meet requirements,
appropriate functionality can be implemented.


\subsection{Parser background}

Before getting into detail about the parser a brief overview is in order.
The parser is split into two parts: the parsing algorithm and the rules
which are applied to the lines.  Rules can be thought of as the Lex part of
a Lex and YACC style parser; rules identify the line and return some data,
which the algorithm (the YACC part) receives, performing the requested
action.  Rules are solely concerned with identifying a line and extracting
data from it, whereas the algorithm's task is to follow the journey each
mail takes through Postfix, piecing the data together into a coherent
whole, and performing housekeeping duties.


\section{Adaptable parsing: user defined rules}

The complexity and variation in Postfix's logs requires similar flexibility
in the parser; decoupling the parsing rules from the associated actions
allows new rules to be written and tested without requiring modifications
to the algorithm source code (significantly lowering the barrier to entry
for new or casual users), and greatly simplifies both algorithm and rules.
It also allows for a clear separation of functionality: rules handle low
level details of identifying and extracting data from a line, whereas the
algorithm handles the higher level details of following the path a mail
takes through postfix, assembling the required data, etc.

Rule have certain characteristics which may help in understanding the
parser:

\begin{itemize}

    \item The first matching rule wins: no further rules are tried against
        that line,\footnote{With one exception, detailed later in Section
        \ref{actions-in-detail}.} but there is a facility for the
        specifying the order of the rules, so that more specific rules can
        be tried first.

    \item Rules are completely self-contained: there are no sub-rules, so
        rules have linear complexity, and can be understood in isolation,
        without reference to any other rules.

    \item XXX EXPAND ON THIS SOME MORE XXX

\end{itemize}

\subsection{Rule attributes}

Each rule defines the following:

\begin{description}

    \item [name] A short name for the rule.

    \item [description] A longer, more detailed description of the rule.

    \item [program] The program (smtp, smtpd, qmgr, etc.) whose log lines
        the rule applies to.  This avoids needlessly trying rules which
        won't match the line, or worse, might match unintentionally.

    \item [restriction\_name] The restriction which caused the mail to be
        rejected.  Only applicable to rules which have a result of
        \texttt{rejected}, other rules will have an empty string.

    \item [regex] The regex to match the log line against.  The regex will
        first have several keywords expanded: this simplifies reading and
        writing rules, avoids needless repetition of complex regex
        components, and allows the components to be corrected and/or
        improved in one location.  For efficiency the keywords are expanded
        and every rule's regex is compiled before attempting to parse the
        log file - otherwise each regex would be recompiled each time it
        was used, resulting in an 468.95\% slowdown.

        Averaged over 10 test runs:

        \begin{itemize} 

            \item Compiled run time was 55.47 seconds, standard deviation
                was 0.247 seconds.

            \item Non-compiled run time was 260.14 seconds (4 minutes,
                20.14 seconds), standard deviation was 0.96 seconds.

        \end{itemize}

        Logging to the database was disabled for the test runs.

    \item [result\_cols, connection\_cols] Specifies how the fields in
        the log line will be extracted.  The format is: \newline
        client\_hostname = 1; recipient = 2; sender = 4; \newline
        i.e. semi-colon separated assignment statements, with the variable
        name on the left and the matching field from the regex on the
        right hand side.

    \item [result\_data, connection\_data] Sometimes rules need to fake a
        piece of data which isn't present in the log line: e.g. setting
        smtp\_code when mail is accepted.  The format is the same as
        result\_cols and connection\_cols, except that arbitrary data can
        be specified rather than just a number.

    \item [result]  XXX RESULT NEEDS TO BE RENAMED XXX This is the action
        Postfix must have taken to generate this line, with two exceptions:

        \begin{itemize}

            \item [info] Represents an unspecified intermediate action that
                the parser is not interested in per se, but which does log
                useful information, supplementing other log lines.

            \item [ignored] An action which is not only uninteresting in
                itself, but which also provides no useful data.

        \end{itemize}

        Uninteresting lines are parsed rather than ignored completely so
        that any lines the parser isn't capable of handling become
        immediately obvious.

    \item [action] The action the algorithm will take, e.g.
        \begin{description}

            \item [ignore] Ignore this line.  The simplest action, it is
                required because every line from a program of interest to
                the parser must be parsed properly; any unparsed line is
                considered an error.

            \item [save\_by\_pid] Use the pid from the log line to lookup a
                connection, then save the data from the log line in the
                connection data structure thus found.

            \item [commit] The mail is finished with, enter it in the
                database, and remove the mail from memory.

        \end{description}

        A full list can be found in Section \ref{actions-in-detail}.

    \item [queueid] Specifies the match from the regex which gives the
        queueid, or zero if the log line doesn't contain a queueid.

    \item [rule\_order] This is an efficiency measure.  This counter is
        maintained for every rule and incremented each time the rule
        successfully matches.  At the start of each run the program sorts
        the rules in descending rule\_order, and at the end of the run
        updates every rule's rule\_order.  Assuming that the 
        distribution of log lines is reasonably consistent, rules matching
        more commonly occurring log lines will be tried before rules
        matching less commonly occurring log lines, lowering the program's
        execution time.

        Averaged over 10 test runs:

        \begin{itemize} 

            \item Ascending order run time was 56.684 seconds, standard
                deviation was 0.29 seconds.

            \item Descending order (reversed) run time was 64.037 seconds,
                standard deviation was 0.16 seconds.

            \item Shuffled order run time was 57.19 seconds, standard
                deviation was 0.95 seconds.

        \end{itemize}

        Logging to the database was disabled for the test runs.

    \item [priority] This is the user-configurable companion to
        rule\_order: rules with a higher priority will be tried first,
        overriding rule\_order, allowing more specific rules to take
        precedence over more general rules.

\end{description}


\subsection{Example rule}

This example rule matches the message Postfix logs when it rejects mail
from a sender address where the domain has neither an MX record nor an A
record, i.e. mail could not be delivered to the sender's address.  
For full details see
http://www.postfix.org/postconf.5.html\#reject\_unknown\_sender\_domain


% Don't reformat this!
\begin{tabular}[]{ll}

name                & Unknown sender domain                             \\
description         & We do not accept mail from unknown domains        \\
program             & postfix/smtpd                                     \\
restriction\_name   & reject\_unknown\_sender\_domain                   \\
regex               & \verb!^<(__SENDER__)>: Sender address rejected: ! \\
                    & \verb!  Domain not found; from=<\1> !             \\
                    & \verb!  to=<(__RECIPIENT__)> proto=E?SMTP !       \\
                    & \verb!  helo=<(__HELO__)>$!                       \\
result\_cols        & recipient = 2; sender = 1                         \\
connection\_cols    & helo = 3                                          \\
result\_data        &                                                   \\
connection\_data    &                                                   \\
result              & REJECTED                                          \\
action              & SAVE\_BY\_PID                                     \\
queueid             & 0                                                 \\
rule\_order         & 0                                                 \\
priority            & 0                                                 \\

\end{tabular}


\section{Parsing algorithm}

While the rules are more than double (treble with 2.3.x rules?) the size of
the algorithm, the rules are quite simple, and each rule is completely
independent of its fellows.  The parser is significantly more complicated,
and highly internally interdependent.


\subsection{Naive approach}

A high level view of the algorithm could be expressed as:

\begin{enumerate}

    \item Mail enters the system via SMTP or local submission.

    \item If the mail is rejected, log all data and finish.

    \item Follow the progress of the accepted mail until it's either delivered or
        bounced, log all data, and finish.

\end{enumerate}

Unfortunately it's not that easy.


\subsection{Complications encountered}

\begin{enumerate}

    \item The mail lacks a queueid until it has been accepted, so log lines
        must first be correlated by the smtpd pid, then transition to being
        correlated by the queueid.  This is relatively minor, but does
        require:

        \begin{itemize}

            \item Two versions of several functions, \texttt{by\_pid} and
                \texttt{by\_queueid}.

            \item Two data structures to hold the data structures for each
                connection.

            \item Most importantly: every section of code must know whether
                it is needs to lookup the data structures by pid or
                queueid.

        \end{itemize}

    \item Multiple independent mails may be delivered during one
        connection: this requires cloning the current data, so that
        subsequent mails won't trample over each other.  This must be done
        every time a mail is accepted, as it's impossible to tell in
        advance which connections will accept multiple mails.  It is quite
        easy to overlook this complication because only a small minority of
        connections accept more than one mail. Happily once the mail has
        been accepted log entries won't be correlated by pid for that mail
        any more (queueid will be used instead), so there isn't any
        ambiguity about which mail a given log line belongs to.  The
        original connection will be discarded unsaved when the client
        disconnects.  One unsolved difficulty is distinguishing between
        different groups of rejections, e.g.

        \begin{enumerate}

            \item The client attempts to deliver a mail, but it is
                rejected.

            \item The client issues the RSET command to reset the session.

            \item The client attempts to deliver another mail, likewise
                rejected.

        \end{enumerate}

        There should probably be two different entires in the database
        resulting from the above sequence, but currently there will only be
        one.

    \item The most difficult complication is that mails are not always
        delivered directly to a mailbox (or program; there is very little
        difference between the two): sometimes they are aliased and
        need to be delivered to an address (or addresses) on another
        server.  When this occurs a child mail will be injected into the
        postfix queue, but without the explicit logging smtpd or sendmail
        injected mails have, so the source is not immediately discernible;
        from a strictly linear reading of the logs it \textit{usually}
        appears as if the child mail has appeared from thin air.
        Subsequently the parent mail will log the creation of the child
        mail:

        \texttt{3FF7C4317: to=<username@example.com>, relay=local, \newline 
        delay=0, status=sent (forwarded as 56F5B43FD)}

        Unfortunately while all log lines from an individual process appear
        in chronological order, the order in which log lines from different
        processes are interleaved is subject to the vagaries of process
        scheduling.  In addition the first log line belonging to the child
        mail (the log line cited above properly belongs to the parent mail)
        is logged by qmgr,\footnote{Qmgr is the Postfix daemon which
        manages the mail queue, determining which mails will have delivery
        attempted next.} so the order also depends on how busy qmgr
        is.\footnote{Postfix is quite paranoid about mail delivery, an
        excellent characteristic for an MTA to possess, so it won't log
        that the child has been created until it is absolutely certain that
        the mail has been written to disk.}

        This has the effect that the parser cannot complain when it
        encounters a log line from qmgr for a previously unseen mail; it
        must mark the mail as potentially fake and subsequently clear the
        faked flag if and when the origin of the mail becomes clear.
        Obviously the parser could omit checking of where mails originate
        from, but I feel that it is better to require an explicit source,
        as bugs are more likely to be exposed.

        Process scheduling can have a still more confusing effect: quite
        often the child mail will be created, delivered and removed
        \textbf{before} the parent logs the creation line!  Thus mails
        marked as faked cannot be entered into the database; instead they
        must be marked as database ready and subsequently entered by the
        parent mail.  Quite apart from identifying mail injected in an
        unknown fashion, or bugs in the parser, faked mails need to be
        marked as such because they lack some data present in the parent
        mail, and must copy that data from their parent.  XXX EITHER REMOVE
        THE LAST LINE OR EXPAND ON IT SOME MORE, AND FIGURE OUT WHY MORE
        DATA ISN'T REQUIRED XXX


\end{enumerate}

\subsection{Algorithm flow chart}

\includegraphics{logparser-flow-chart.ps}
\label{flow-chart}

\subsection{Full algorithm}

\label{full-algorithm}


\subsection{Actions in detail}

\label{actions-in-detail}


\section{Limitations and possible improvements}

Every piece of software suffers from some limitations, and there is almost
always room for improvement.

\subsection{Limitations}

\begin{itemize}

    \item Each new Postfix release requires new rules to be written, to
        cope with the new messages.

    \item The program should save state at the end of each run, and reload
        it at the start of the next run, to properly cope with mails which
        span logs.  This might also require purging old mails once they've
        been in the state tables for too long.

    \item It appears that the hostname used in the HELO command is not
        logged if the mail is accepted.\footnote{Tested with Postfix
        2.2.10, this may possibly have changed in Postfix 2.3, or the
        upcoming 2.4.}

\end{itemize}

\subsection{Possible improvements}
\begin{itemize}

    \item A progress bar would be useful when run interactively, as the
        program takes roughly one minute per 10MB of
        logs.\footnote{Approximately 80\% of the run time is consumed by
        logging to the database.}  Obviously performance is entirely
        dependant on the machine the program is running on.

\end{itemize}

\section{Conclusion}

\appendix



\end{document}
