% $Id$
\documentclass[a4paper,12pt,draft]{article}

% Better typesetting of URLs.
\usepackage{url}
% Include images
\usepackage[final]{graphicx}

\begin{document}

\title{Parsing Postfix log files}
\author{John Tobin \\ School of Computer Science and Statistics \\ 
Trinity College \\ Dublin 2 \\ Ireland \\ tobinjt@cs.tcd.ie}
\date{}
\maketitle

\begin{abstract}

    Parsing Postfix logs is much more difficult than it first appears but
    it is possible.  This paper describes the process required, documenting
    the parsing algorithm and rules, explaining the difficulties
    encountered, with reference to an implementation which stores data
    gathered from the logs in an SQL database for later processing.

\end{abstract}

XXX WHAT IS THE CONCLUSION??? XXX

\newpage
\tableofcontents

\section{Introduction}

Most mail server administrators will have performed some basic processing
of Postfix logs at one time or another, whether it was to debug a problem,
explain to a user why their mail is being rejected, or to check whether
their new anti-spam measures are working.  The more adventurous will have
generated some statistics to show how many hits each of their anti-spam
measures has gotten in the last week, and possibly even generated some
graphs to clearly illustrate the point to management or complaining
users.\footnote{This was the author's first real foray into processing
Postfix logs.}  Very few will have performed in-depth parsing and analysis
of their logs, where the parsing must correlate the log lines
per-connection or per-queueid, rather than processing lines independently.
One of the barriers to this type of processing is the unstructured nature
of Postfix's logs, where each logging line was added on an ad hoc basis as
a requirement was discovered or new functionality was added.  Further
complication arises as a result of the facility to have rejection messages
defined by the administrator, and every Real-time Black List returns a
different explanatory message.  This paper documents the difficult process
of parsing Postfix logs, and presents a program which parses logs and
places the resulting data into a database for further processing by other
applications.


\section{Background}

\subsection{Postfix background}

Postfix is a highly configurable, high performance, secure and scalable
Mail Transport Agent.  It features extensive anti-spam restrictions,
allowing a mail administrator to deploy those restrictions which they judge
suitable for their needs, rather than a fixed set chosen by Postfix's
author.  These restrictions can be selectively applied, combined and
bypassed on a per-client, per-recipient or per-sender basis, allowing
varying levels of defense and or permissiveness.  Postfix leverages simple
lookup tables to support arbitrarily complicated user-defined sequences of
restrictions and exceptions, with the ultimate in flexibility being the
facility to consult an external process which can implement whatever logic
is required: some users can be restricted to sending mail on the third
Tuesday after pay day only, if that is of any use.\footnote{This example
may actually be useful in a payroll system.  More commonly encountered
scenarios are restricting posting to large mailing lists (e.g.\ sending
weekly offers to customers) to out of office hours, rate limiting clients,
or checking SPF records (see http://www.openspf.org/ or
http://en.wikipedia.org/wiki/Sender\_Policy\_Framework for details)}
Administrators can also supply their own rejection messages, to make it
clear to senders why exactly their mail was rejected.  Unfortunately this
flexibility has a cost: complexity in the logs generated.  While it is easy
to use \texttt{grep(1)} to determine the fate of an individual email,
following the journey an email takes through Postfix can be quite
difficult.  The logs tend to follow a 90\%-10\% pattern: 90\% of the time
the journey is simple, but the other 10\% of the time requires 90\% of the
code.\footnote{These numbers don't have a solid scientific basis, they're
based on gut feeling from writing and debugging the software.}

\subsection{Paper background}

This paper and the program it describes are part of a larger project to
optimise a server's Postfix restrictions, generate statistics and graphs,
and provide a platform on which new restrictions can be trialled and
evaluated to see if they are worth using in the fight against spam.  The
program parses Postfix logs and populates a database with the data gleaned
from those logs, providing a consistent and simple view of the logs which
future tools can utilise.  The program should be reasonably easily
extensible, so if logging to a database doesn't meet requirements,
appropriate functionality can be implemented.


\subsection{Parser background}

Before getting into detail about the parser a brief overview is in order.
The parser is split into two parts: the parsing algorithm and the rules
which are applied to the lines.  Rules can be thought of as the Lex part of
a Lex and YACC style parser; rules identify the line and return some data,
which the algorithm (the YACC part) receives, performing the requested
action.  Rules are solely concerned with identifying a line and extracting
data from it, whereas the algorithm's task is to follow the journey each
mail takes through Postfix, piecing the data together into a coherent
whole, and performing housekeeping duties.


\subsection{Assumptions}

The algorithm described and the program implementing it make a small number
of (hopefully safe and reasonable) assumptions:

\begin{itemize}

    \item The logs are whole and complete; nothing has been removed, either
        deliberately or accidentally (e.g.\ log rotation gone awry, file
        system filling up, logging unable to cope with the volume of logs).

    \item Postfix logs sufficient information to make it possible to
        accurately reconstruct the actions it has taken.

    \item The Postfix queue has not been tampered with, causing unexplained
        appearance or disappearance of mail.

\end{itemize}

In some ways this task is similar to reverse engineering a program, or
replicating a black box program based solely on its inputs and outputs.
Although the source code is available, reading and understanding it would
require a significant investment of time:

\begin{tabular}[]{lll}

    Postfix 2.3.8   & Postfix 2.4.0 &                   \\
    82224           & 83965         & lines of code     \\
    67146           & 68675         & lines of comments \\
    17647           & 18069         & lines are blank   \\
    167017          & 170709        & lines in total    \\

\end{tabular}


\section{Adaptable parsing: user defined rules}

The complexity and variation in Postfix's logs requires similar flexibility
in the parser; decoupling the parsing rules from the associated actions
allows new rules to be written and tested without requiring modifications
to the algorithm source code (significantly lowering the barrier to entry
for new or casual users), and greatly simplifies both algorithm and rules.
It also allows for a clear separation of functionality: rules handle low
level details of identifying and extracting data from a line, whereas the
algorithm handles the higher level details of following the path a mail
takes through postfix, assembling the required data, etc.

Rule have certain characteristics which may help in understanding the
parser:

\begin{itemize}

    \item The first matching rule wins: no further rules are tried against
        that line,\footnote{With one exception, details are provided later
        in Section~\ref{actions-in-detail}.} but there is a facility for
        the specifying the order of the rules, so that more specific rules
        can be tried first.

    \item Rules are completely self-contained: there are no sub-rules, so
        rules have linear complexity, and can be understood in isolation,
        without reference to any other rules.

    \item XXX EXPAND ON THIS SOME MORE XXX

\end{itemize}

\subsection{Rule attributes}

Each rule defines the following:

\begin{description}

    \item [name] A short name for the rule.

    \item [description] A longer, more detailed description of the rule.

    \item [program] The program (smtp, smtpd, qmgr, etc.) whose log lines
        the rule applies to.  This avoids needlessly trying rules which
        won't match the line, or worse, might match unintentionally.

    \item [restriction\_name] The restriction which caused the mail to be
        rejected.  Only applicable to rules which have a result of
        \texttt{rejected}, other rules will have an empty string.

    \item [regex] The regex to match the log line against.  The regex will
        first have several keywords expanded: this simplifies reading and
        writing rules, avoids needless repetition of complex regex
        components, and allows the components to be corrected and/or
        improved in one location.  For efficiency the keywords are expanded
        and every rule's regex is compiled before attempting to parse the
        log file --- otherwise each regex would be recompiled each time it
        was used, resulting in an 468.95\% slowdown.

        Averaged over 10 test runs:

        \begin{itemize} 

            \item Compiled run time was 55.47 seconds, standard deviation
                was 0.247 seconds.

            \item Non-compiled run time was 260.14 seconds (4 minutes,
                20.14 seconds), standard deviation was 0.96 seconds.

        \end{itemize}

        Logging to the database was disabled for the test runs.

    \item [result\_cols, connection\_cols] Specifies how the fields in the
        log line will be extracted.  The format is: \newline
        client\_hostname = 1; recipient = 2; sender = 4; \newline
        i.e. semi-colon separated assignment statements, with the variable
        name on the left and the matching field from the regex on the right
        hand side.

    \item [result\_data, connection\_data] Sometimes rules need to fake a
        piece of data which isn't present in the log line: e.g.\ setting
        smtp\_code when mail is accepted.  The format is the same as
        result\_cols and connection\_cols, except that arbitrary data can
        be specified rather than just a number.

    \item [result]  XXX RESULT NEEDS TO BE RENAMED XXX This is the action
        Postfix must have taken to generate this line, with two exceptions:

        \begin{itemize}

            \item [info] Represents an unspecified intermediate action that
                the parser is not interested in per se, but which does log
                useful information, supplementing other log lines.

            \item [ignored] An action which is not only uninteresting in
                itself, but which also provides no useful data.

        \end{itemize}

        Uninteresting lines are parsed rather than ignored completely so
        that any lines the parser isn't capable of handling become
        immediately obvious.

    \item [action] The action the algorithm will take, e.g.
        \begin{description}

            \item [ignore] Ignore this line.  The simplest action, it is
                required because every line from a program of interest to
                the parser must be parsed properly; any unparsed line is
                considered an error.

            \item [save\_by\_pid] Use the pid from the log line to lookup a
                connection, then save the data from the log line in the
                connection data structure thus found.

            \item [commit] The mail is finished with, enter it in the
                database, and remove the mail from memory.

        \end{description}

        A full list can be found in Section~\ref{actions-in-detail}.

    \item [queueid] Specifies the match from the regex which gives the
        queueid, or zero if the log line doesn't contain a queueid.

    \item [rule\_order] This is an efficiency measure.  This counter is
        maintained for every rule and incremented each time the rule
        successfully matches.  At the start of each run the program sorts
        the rules in descending rule\_order, and at the end of the run
        updates every rule's rule\_order.  Assuming that the distribution
        of log lines is reasonably consistent, rules matching more commonly
        occurring log lines will be tried before rules matching less
        commonly occurring log lines, lowering the program's execution
        time.

        Averaged over 10 test runs:

        \begin{itemize} 

            \item Ascending order run time was 56.684 seconds, standard
                deviation was 0.29 seconds.

            \item Descending order (reversed) run time was 64.037 seconds,
                standard deviation was 0.16 seconds.

            \item Shuffled order run time was 57.19 seconds, standard
                deviation was 0.95 seconds.

        \end{itemize}

        Logging to the database was disabled for the test runs.

    \item [priority] This is the user-configurable companion to
        rule\_order: rules with a higher priority will be tried first,
        overriding rule\_order, allowing more specific rules to take
        precedence over more general rules.

\end{description}


\subsection{Example rule}

This example rule matches the message Postfix logs when it rejects mail
from a sender address where the domain has neither an MX record nor an A
record, i.e.\ mail could not be delivered to the sender's address.  For full
details see
http://www.postfix.org/postconf.5.html\#reject\_unknown\_sender\_domain

XXX CARL SUGGESTS EXPANDING ON THIS SOME MORE, BUT I DON'T KNOW HOW\@.
PERHAPS WHEN THE ALGORITHM IS EXPLAINED\@? XXX

% Don't reformat this!
\begin{tabular}[]{ll}

name                & Unknown sender domain                             \\
description         & We do not accept mail from unknown domains        \\
program             & postfix/smtpd                                     \\
restriction\_name   & reject\_unknown\_sender\_domain                   \\
regex               & \verb!^<(__SENDER__)>: Sender address rejected: ! \\
                    & \verb!  Domain not found; from=<\1> !             \\
                    & \verb!  to=<(__RECIPIENT__)> proto=E?SMTP !       \\
                    & \verb!  helo=<(__HELO__)>$!                       \\
result\_cols        & recipient = 2; sender = 1                         \\
connection\_cols    & helo = 3                                          \\
result\_data        &                                                   \\
connection\_data    &                                                   \\
result              & REJECTED                                          \\
action              & SAVE\_BY\_PID                                     \\
queueid             & 0                                                 \\
rule\_order         & 0                                                 \\
priority            & 0                                                 \\

\end{tabular}


\section{Parsing algorithm}

While the rules are more than double (treble with 2.3.x rules?) the size of
the algorithm, the rules are quite simple and each rule is completely
independent of its fellows.  The parser is significantly more complicated,
and highly internally interdependent.


\subsection{Naive approach}

A high level view of the algorithm could be expressed as:

\begin{enumerate}

    \item Mail enters the system via SMTP or local submission.

    \item If the mail is rejected, log all data and finish.

    \item Follow the progress of the accepted mail until it's either delivered or
        bounced, log all data, and finish.

\end{enumerate}

Unfortunately it's not that easy.


\subsection{Complications encountered}

\begin{enumerate}

    \item The mail lacks a queueid until it has been accepted, so log lines
        must first be correlated by the smtpd pid, then transition to being
        correlated by the queueid.  This is relatively minor, but does
        require:

        \begin{itemize}

            \item Two versions of several functions, \texttt{by\_pid} and
                \texttt{by\_queueid}.

            \item Two data structures to hold the data structures for each
                connection.

            \item Most importantly: every section of code must know whether
                it is needs to lookup the data structures by pid or
                queueid.

        \end{itemize}

    \item Multiple independent mails may be delivered during one
        connection: this requires cloning the current data, so that
        subsequent mails won't trample over each other.  This must be done
        every time a mail is accepted, as it's impossible to tell in
        advance which connections will accept multiple mails.  It is quite
        easy to overlook this complication because only a small minority of
        connections accept more than one mail. Happily once the mail has
        been accepted log entries won't be correlated by pid for that mail
        any more (queueid will be used instead), so there isn't any
        ambiguity about which mail a given log line belongs to.  The
        original connection will be discarded unsaved when the client
        disconnects.  One unsolved difficulty is distinguishing between
        different groups of rejections, e.g.

        \begin{enumerate}

            \item The client attempts to deliver a mail, but it is
                rejected.

            \item The client issues the RSET command to reset the session.

            \item The client attempts to deliver another mail, likewise
                rejected.

        \end{enumerate}

        There should probably be two different entires in the database
        resulting from the above sequence, but currently there will only be
        one.

    \item The most difficult complication is that mails are not always
        delivered directly to a mailbox (or program; there is very little
        difference between the two): sometimes they are aliased and
        need to be delivered to an address (or addresses) on another
        server.  When this occurs a child mail will be injected into the
        postfix queue, but without the explicit logging smtpd or sendmail
        injected mails have, so the source is not immediately discernible;
        from a strictly linear reading of the logs it \textit{usually\/}
        appears as if the child mail has appeared from thin air.
        Subsequently the parent mail will log the creation of the child
        mail:

        \texttt{3FF7C4317: to=<username@example.com>, relay=local, \newline 
        delay=0, status=sent (forwarded as 56F5B43FD)}

        Unfortunately while all log lines from an individual process appear
        in chronological order, the order in which log lines from different
        processes are interleaved is subject to the vagaries of process
        scheduling.  In addition the first log line belonging to the child
        mail (the log line cited above properly belongs to the parent mail)
        is logged by qmgr,\footnote{Qmgr is the Postfix daemon which
        manages the mail queue, determining which mails will have delivery
        attempted next.} so the order also depends on how busy qmgr
        is.\footnote{Postfix is quite paranoid about mail delivery, an
        excellent characteristic for an MTA to possess, so it won't log
        that the child has been created until it is absolutely certain that
        the mail has been written to disk.}

        This has the effect that the parser cannot complain when it
        encounters a log line from qmgr for a previously unseen mail; it
        must mark the mail as potentially fake and subsequently clear the
        faked flag if and when the origin of the mail becomes clear.
        Obviously the parser could omit checking of where mails originate
        from, but I feel that it is better to require an explicit source,
        as bugs are more likely to be exposed.

        Process scheduling can have a still more confusing effect: quite
        often the child mail will be created, delivered and removed
        \textbf{before} the parent logs the creation line!  Thus mails
        marked as faked cannot be entered into the database; instead they
        must be marked as database ready and subsequently entered by the
        parent mail.  Quite apart from identifying mail injected in an
        unknown fashion, or bugs in the parser, faked mails need to be
        marked as such because they lack some data present in the parent
        mail, and must copy that data from their parent.  XXX EITHER REMOVE
        THE LAST LINE OR EXPAND ON IT SOME MORE, AND FIGURE OUT WHY MORE
        DATA ISN'T REQUIRED XXX


\end{enumerate}

\subsection{Flow chart}

\label{flow-chart}

This flow chart shows the paths the data representing a mail/connection can
take through the parser algorithm.

\includegraphics{logparser-flow-chart.ps}

\subsection{Full algorithm}

\label{full-algorithm}

The intermingling of log entries from different mails immediately rules out
the possibility of handling each mail in isolation; the parser must be
capable of handling multiple mails in parallel, each potentially at a
different stage in its journey, without any interference between mails ---
except in the minority of cases where intra-mail interference is required.
I felt that the best way to implement this was to maintain state
information for every unfinished mail and manipulate it appropriately for
each log line encountered.  The parser thus requires both a method of
mapping log lines to the correct mail and a method of specifying the action
the log line represents.  The former is achieved by using the pid of the
smtpd during the initial phase, then switching to the queueid once the mail
has been accepted.  The latter uses the action field of the rule which
matched the log line, executing the code in the function named by the
action.  From a high level viewpoint this design shares significant
similarity with how an editor maintains state for multiple files and
performs the actions the user initiates on the correct file.

XXX USE A DISPATCH TABLE TO MAKE THIS ACCURATE XXX

Section~\ref{actions-in-detail} explains the actions in substantive detail;
this section will omit such detail because it would clutter and confuse the
algorithm description.  The flow chart in section~\ref{flow-chart} should
be consulted also.

\subsubsection{Mail enters the system}

\label{mail-enters-the-system}

Everything starts off with a mail entering the system, by local submission
via postdrop/sendmail, by SMTP, or by re-injection due to forwarding.
Local submission is the simplest of the three: a queueid is assigned
immediately and the sender address is logged (action: pickup;
flowchart:~2).  SMTP is more complicated: 

\begin{enumerate}
        
    \item First there is a connection from the remote client
        (action: connect; flowchart:~1).

    \item This is followed either by rejections (action: save\_by\_pid;
        flowchart:~4) or acceptance of one or more mails (action: clone,
        then save\_by\_pid; flowchart:~5,~4), or a combination of both.
        
    \item The client disconnects (action: disconnect; flowchart:~6).  As
        soon as a mail is accepted it is assigned a queueid; if there is no
        queueid Postfix didn't accept any mail over that connection, it
        rejected all attempts due to the configured restrictions.  Absence
        of a queueid is checked for during disconnection handling (action:
        still disconnect; flowchart:~7) and if none is found the data is
        cleaned up and entered in the database (action: still disconnect;
        flowchart:~8; subroutines: fixup\_connection and
        commit\_connection), then removed from memory (action: still
        disconnect; flowchart:~9).

    \item If one or more mails were accepted there will be more log entries
        later.

\end{enumerate}

Re-injection due to forwarding sadly lacks explicit log lines of its own;
there are two implicit indications:

\begin{enumerate}

    \item The more commonly occurring indicator is qmgr selecting a mail
        with a previously unseen queueid for delivery (action:
        qmgr\_chooses\_mail; flowchart:~3), in which case a new data
        structure will be created.  The mail will be marked as faked; this
        flag should be subsequently cleared.  The data is then saved
        (action: still qmgr\_chooses\_mail; flowchart:~3).  

    \item This indicator will be seen for every mail that is re-injected
        but is less common in identifying re-injected mail because it
        typically occurs after the indicator explained above.  Local
        delivery re-injects the mail and logs a successful delivery rather
        than delivering directly to a mailbox or program (action: track;
        flowchart:~11).  In this case the mail may already have been
        created (by qmgr\_chooses\_mail, above); if not a new data
        structure will be created.  In both cases the new mail is marked as
        a child of the parent.

\end{enumerate}

Re-injection is somewhat awkward to explain because it overlaps both the
mail entering and mail delivery sections.  See
section~\ref{tracking-re-injected-mail} for a full discussion.

\subsubsection{Mail delivery}

The obvious counterpart to mail entering the system is mail leaving the
system, whether it is by deletion, bouncing or delivery.  All three are
handled in exactly the same way:

\begin{enumerate}

    \item The sender and recipient addresses will be logged separately
        (action: save\_by\_queueid; flowchart:~10).

    \item Sometimes mail is re-injected and the child mail needs to be
        tracked by the parent mail (action: track; flowchart:~11) --- see
        section~\ref{tracking-re-injected-mail}.

    \item Eventually the mail will be delivered (even if re-injected),
        bounced, or deleted by the administrator (action: commit;
        flowchart:~12).  This is the last line in the logs for this
        particular mail (it may be indirectly referred to if it was
        re-injected).  If it is neither parent nor child of re-injection
        the data is cleaned up and entered in the database (action: still
        commit; flowchart:~14), then deleted from memory (action: still
        commit; flowchart:~15).  For re-injected mails see 
        section~\ref{tracking-re-injected-mail}.

\end{enumerate}

I'd like to reiterate that the actions above happen whether the mail is
delivered to a mailbox, piped to a command, delivered to a remote server,
bounced (due to a mail loop, delivery failure, or five day timeout), or
deleted by the administrator.  The exception is when the mail is
re-injected due to forwarding, and that deserves its own section, which is
coming up next.

\subsubsection{Tracking re-injected mail}

\label{tracking-re-injected-mail}

It's probably apparent by now that tracking re-injected mails is the single
most complex part of the parser.

\subsection{Actions in detail}

\label{actions-in-detail}


\begin{description}

    \item [ignore] Ignore this line, so that all log lines we're interested
        in are parsed, but this line doesn't have any effect.

    \item [connect] Handle a connection from a remote client.  Complains if
        a connection already exists for this client

    \item [disconnect] 

    \item [save\_by\_pid] 

    \item [save\_by\_queueid] 

    \item [commit] 

    \item [track] 

    \item [restriction\_start] 

    \item [qmgr\_chooses\_mail] 
        however qmgr selects every mail for delivery, so most of the time
        this action merely falls through to saving the information from the
        log line (action: save\_by\_queueid; flowchart:~10).

    \item [pickup] 

    \item [clone] 

\end{description}


\section{Limitations and possible improvements}

Every piece of software suffers from some limitations, and there is almost
always room for improvement.

\subsection{Limitations}

\begin{itemize}

    \item Each new Postfix release requires new rules to be written, to
        cope with the new messages.

    \item The program should save state at the end of each run, and reload
        it at the start of the next run, to properly cope with mails which
        span logs.  This might also require purging old mails once they've
        been in the state tables for too long, though the presence of very
        old mails indicates a bug in either the implementation or the
        specification.

    \item It appears that the hostname used in the HELO command is not
        logged if the mail is accepted.\footnote{Tested with Postfix
        2.2.10; this may possibly have changed in Postfix 2.3, or the
        upcoming 2.4.}  It should be reasonably simple to write a policy
        server which causes Postfix to log a warning containing the HELO
        hostname when the DATA command is accepted.

    \item The algorithm does not distinguish between mails where one or
        more mails are rejected and a subsequent mail is accepted; it will
        appear in the database as one mail with lots of rejections followed
        by acceptance.  I don't believe it's possible to make this
        distinction given the data Postfix logs, though it might be
        possible to write a policy server to provide additional logging.

\end{itemize}

\subsection{Possible improvements}
\begin{itemize}

    \item A progress bar would be useful when run interactively, as the
        program takes roughly one minute per 10MB of
        logs.\footnote{Approximately 80\% of the run time is consumed by
        logging to the database.}  Obviously performance is entirely
        dependant on the machine the program is running on.

    \item Write the policy server referred to in the third limitation
        above.

\end{itemize}

\section{Conclusion}

\appendix



\end{document}
