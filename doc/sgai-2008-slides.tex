\documentclass{beamer}
%\mode<presentation>
%{
%  \usetheme{Warsaw}
%  % or ...
%
%  \setbeamercovered{transparent}
%  % or whatever (possibly just delete it)
%}
\useoutertheme{infolines}
\defbeamertemplate*{headline}{JT theme}{}

\usepackage[english]{babel}
% or whatever

\usepackage[latin1]{inputenc}
% or whatever

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

\newcommand{\timingnote}[1]{%
    \textbf{#1}%
}

\title{A User-Extensible and Adaptable Parser Architecture}

\author[John Tobin \and Carl Vogel]{John Tobin \and Carl Vogel\\
    tobinjt@cs.tcd.ie vogel@cs.tcd.ie}
% - Give the names in the same order as the appear in the paper.
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[Trinity College]
{
    School of Computer Science and Statistics,\\
    Trinity College, University of Dublin
}

\date[SGAI 2008]{Twenty-eighth SGAI International Conference on Artificial Intelligence}

\subject{Theoretical Computer Science}

% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}


\begin{document}

\begin{frame}
    \timingnote{30 seconds}
    \titlepage{}
\end{frame}

\begin{frame}{Outline Of This Talk}
    \timingnote{30 seconds --- 1 minute}
    \tableofcontents{}
\end{frame}


% Structuring a talk is a difficult task and the following structure
% may not be suitable. Here are some rules that apply for this
% solution: 

% - Exactly two or three sections (other than the summary).
% - At *most* three subsections per section.
% - Talk about 30s to 2min per frame. So there should be between about
%   15 and 30 frames, all told.

% - A conference audience is likely to know very little of what you
%   are going to talk about. So *simplify*!
% - In a 20min talk, getting the main ideas across is hard
%   enough. Leave out details, even if it means being less precise than
%   you think necessary.
% - If you omit details that are vital to the proof/implementation,
%   just say so once. Everybody will be happy with that.

\section{Background}

\begin{frame}{Background}

    \timingnote{1--2 minutes}

    This parser architecture was developed as part of a larger project to
    improve anti-spam techniques.

    \begin{description}

        \item [Currently] Most commonly used anti-spam techniques are
            content-based, and require each mail to be accepted before
            determining its spam status.

        \item [However] Rejecting mail at SMTP-time is more efficient, and
            senders of non-spam mails that are incorrectly rejected will
            receive a bounce notification immediately.

        \item [Project Aim] To improve SMTP-time anti-spam techniques, by
            providing a platform for reasoning about anti-spam techniques.

        \item [Method] Parse Postfix log files and analyse the
            extracted data.

        \item [Conclusion] This method requires a parser for Postfix log
            files.

    \end{description}

\end{frame}

\section{Input Characteristics}

\begin{frame}{Input Characteristics}

    \timingnote{1 minute}

    \begin{itemize}

        \item Postfix log lines change over time and from site to site, so
            it must be easy for the end user to parse new log lines.

        \item The processing required for a type of log line (e.g.\
            rejecting a mail delivery attempt) rarely changes, but it can
            be quite complex.

        \item By separating parsing of log lines from processing of log
            lines, we can make parsing new or changed log lines as easy as
            possible, while still allowing for complicated processing when
            necessary.

    \end{itemize}

    Sample log line: \texttt{NOQUEUE\@: reject: RCPT from
    client.example.net[192.0.2.1]: 554 5.7.1 <alice@example.net>: Relay
    access denied; from=<eve@example.com> to=<alice@example.net> proto=SMTP
    helo=<client.example.com>}

\end{frame}


\section{Architecture}

\begin{frame}{Architecture}

    \timingnote{2 minutes}

    The architecture is divided into three parts:

    \begin{description}

        \item [Framework] The framework manages rules and provides support
            functions to actions, e.g.\ data storage, inter-action
            communication, and utility functions.  For each input log line,
            the framework tries each rule in turn until one matches, then
            it invokes the action specified by the rule.

        \item [Actions] Each action performs the processing required, e.g.\
            create a new data structure when a client connects; record than
            an anti-spam measure was successful; commit the data structure
            when all processing is complete.

        \item [Rules] Each rule matches one type of log line, e.g.\ the log
            line resulting from client connecting, a mail successfully
            delivered, or a mail rejected by an anti-spam measure.

    \end{description}

\end{frame}

\section{Features of the Architecture}

\begin{frame}{Features of the Architecture}

    \timingnote{2 minutes}

    \begin{itemize}

        \item The architecture is capable of parsing inputs that are not
            completely understood, e.g.\ when developing a parser: the
            framework will warn about unparsed inputs but will continue on
            parsing as best it can.  \timingnote{Emphasise this.}

        \item Rules can be tagged with conditions which must hold before
            the rule will be used to match an input.

        \item The parser does not need to be recompiled when rules are
            changed, allowing: quicker testing of modified rules; easing
            interchange of rulesets; combining two or more rulesets.

        \item Cascaded Parsing.

        \item Rules can be changed or added by actions while the parser is
            running, allowing dynamically changing parsing, e.g.\ macros.
            This feature must be used with care.  \timingnote{Currying
            functions in a calculator might be a good example.}

    \end{itemize}

\end{frame}


\section{Results}

\begin{frame}{Results}

    \timingnote{1--2 minutes}

    \begin{itemize}

        \item 100\% coverage of log lines.

        \item 100\% coverage of all mails accepted, delivered, or rejected.

        \item 169 rules parsing 522 contiguous log files: the top 10\% of
            the rules match 85.03\% of the log lines, the remainder tailing
            off similar to a Power Law distribution.

        \item Most actions are triggered by only one or two rules.

        \item The top three actions are triggered by 41, 49, and 59 rules.
            \timingnote{build/stats-action-distribution}
            \timingnote{uninteresting, save\_data, delivery\_rejected}

        \item XXX MORE\@?

    \end{itemize}

\end{frame}

\section{Efficiency}

\begin{frame}{Efficiency}

    \timingnote{2 minutes}

    \begin{itemize}

        \item Median throughput is 80.85~MB (480,569 log lines) parsed per
            minute.

        \item Rules are tagged with the name of a Postfix component, and
            will only be used to parse log lines produced by that
            component.

        \item Rules are sorted by how frequently they match, resulting in a
            mean reduction of 14.78\% in parsing time compared to using
            unsorted rules.

        \item The architecture scales extremely well as the number of rules
            increases: a 46.05\% increase in the Postfix ruleset ($115
            \rightarrow{} 169$ rules) resulted in a mean increase of 0.63\%
            in parsing time.

        \item Parsing time scales linearly with input size, but
            \textit{is\/} affected by input content.

    \end{itemize}

\end{frame}

\section{Future Directions}

\begin{frame}{Future Directions}

    \timingnote{1--2 minutes}

    \begin{itemize}

        \item Data mining to determine how well each anti-spam technique
            works.

        \item Data mining to search for combinations of features which can
            be used to detect spam, and development of new anti-spam
            techniques to defeat such spam.

        \item Use Machine Learning techniques instead of writing rules;
            Instance Based Learning techniques must be used due to the size
            of the data set.  \timingnote{Compare to SLCT-based tool.}

        \item Detection of overlapping rules: intersection of Finite
            Automata or Push-Down Automata.

        \item Provide a reference implementation.

    \end{itemize}

\end{frame}


\section{Summary}

\begin{frame}{Summary}

    \timingnote{1 minute}

    \begin{itemize}

        \item Easy to develop a flexible yet strict parser.

        \item Easy for users to parse new or changed inputs.

        \item Parser can still be efficient and fast.

    \end{itemize}

    \timingnote{remainder}

    \begin{itemize}

        \item Questions?

        \item Comments?

    \end{itemize}

\end{frame}

\end{document}
