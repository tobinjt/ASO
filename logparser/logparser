#!/usr/bin/env perl

# $Id$

use strict;
use warnings;

use Time::HiRes qw(gettimeofday tv_interval);
my $start_time;
BEGIN {
    $start_time = [gettimeofday()];
}

use lib q{..};
use ASO::DB;
use ASO::Parser;
use Getopt::Long;
use Pod::Usage;
use File::Temp qw(tempfile);

# Required under Windows.
binmode STDOUT;
binmode STDERR;
$| = 1;

my ($Options, $parser_options) = get_options();

# Ensure that we don't try to read from a terminal.
my @logs = @ARGV;
if (not @logs and -t STDIN) {
    die qq{Usage: $0 logfile [logfiles]\n};
}
if (not @logs) {
    @logs = q{-};
}
my $timing_file;
if ($Options->{q{timing-data}}) {
    $timing_file = IO::File->new(q{> } . $Options->{q{timing-data}})
        or die qq{$0: failed opening } . $Options->{q{timing-data}} . qq{: $!\n};
}

# Save the startup times separately, when profiling with Devel::Profile.
devel_profile_startup();
# Restrict the packages Devel::SmallProf will report about.
set_SmallProf_packages();

my $finished_loading = [gettimeofday()];
print_timing(q{Loaded modules}, q{}, tv_interval($start_time, $finished_loading));

warn qq{vim: set foldmethod=marker :\n};
my $parser = ASO::Parser->new($parser_options);
$parser->load_rules();
my $parser_created = [gettimeofday()];
print_timing(q{Parser created}, q{}, tv_interval($finished_loading, $parser_created));

if ($Options->{q{in-statefile}}) {
    $parser->load_state($Options->{q{in-statefile}});
}
my $state_loaded = [gettimeofday()];
print_timing(q{State loaded}, q{}, tv_interval($parser_created, $state_loaded));

foreach my $logfile (@logs) {
    timewarn(qq{Starting to read $logfile\n});
    my $parse_starting = [gettimeofday()];
    $parser->parse($logfile);
    my $parse_finished = [gettimeofday()];
    print_timing(qq{Parsed logfile}, $logfile,
        tv_interval($parse_starting, $parse_finished));

    $parser->post_parsing();
    my $post_parsing_finished = [gettimeofday()];
    print_timing(qq{Post parse}, $logfile,
        tv_interval($parse_finished, $post_parsing_finished));

    my $statefile = IO::File->new(q{>} . $Options->{q{out-statefile}})
        or die qq{Failed to open $Options->{q{out-statefile}}: $!\n};
    $parser->dump_state($statefile);
    my $dump_finished = [gettimeofday()];
    print_timing(qq{Dumped state}, $logfile,
        tv_interval($parse_finished, $dump_finished));
}

timewarn(qq{Updating hits\n});
my $update_starting = [gettimeofday()];
$parser->update_check_order();
my $update_finished = [gettimeofday()];
print_timing(qq{Updated hits}, q{}, tv_interval($update_starting, $update_finished));

# Some profiling modules dump their data to stdout, but we want to redirect
# that.  If the correct environment variable is set stdout will be redirected
# here and the data will go to the requested file.
redirect_stdout();
my $finished = [gettimeofday()];
print_timing(qq{Total time}, q{}, tv_interval($start_time, $finished));

exit 0;

sub devel_profile_startup {
    if (exists $ENV{PERL_PROFILE_SAVETIME}) {
        DB::reset();
        my $filename;
        if (exists $ENV{PERL_PROFILE_FILENAME}) {
            $filename = $ENV{PERL_PROFILE_FILENAME};
        } else {
            $filename = q{prof.out};
        }
        rename $filename, qq{$filename.startup}
            or warn qq{$0: failed renaming $filename: $!\n};
    }
}

sub set_SmallProf_packages {
    if (exists $INC{q{Devel/SmallProf.pm}}) {
        # Silence warnings about it only being used once.
        %DB::packages = ();
        %DB::packages = (
            q{main}                     => 1,
            q{ASO::DB}                  => 1,
            q{ASO::DB::Connection}      => 1,
            q{ASO::DB::Result}          => 1,
            q{ASO::DB::Rule}            => 1,
            q{ASO::Parser}              => 1,
            q{ASO::ProgressBar}         => 1,
            q{ASO::ProgressBar::Dummy}  => 1,
        );
    }
}

sub redirect_stdout {
    if (exists $ENV{REDIRECT_STDOUT}) {
        close STDOUT;
        open STDOUT, qq{> $ENV{REDIRECT_STDOUT}};
    }
}

sub get_options {
    # Start by extracting options from ASO::Parser.
    my @switches;
    my $parser_options = ASO::Parser::options_for_new();
    foreach my $option_type (keys %$parser_options) {
        if ($option_type =~ /toggle$/) {
            push @switches, map { qq{$_!} }
                keys %{$parser_options->{$option_type}};
        } elsif ($option_type =~ /argument$/) {
            push @switches, map { qq{$_=s} }
                keys %{$parser_options->{$option_type}};
        } else {
            die qq{$0: unknown option type $option_type\n};
        }
    }

    # Add logparser options.
    my %logparser_options = (
        q{in-statefile|i=s}         => undef,
        q{out-statefile|o=s}        => q{state},
        q{timing-data|t=s}          => undef,
        q{help|h}                   => 0,
        q{version|v}                => 0,
    );
    push @switches, keys %logparser_options;

    # Now, default values.
    my %parser_defaults = (
        data_source => q{dbi:SQLite:dbname=../sql/db.sq3},
    );
    my %logparser_defaults = getopt_to_key(%logparser_options);

    # Finally process the command line.
    my %opts = (
        %parser_defaults,
        %logparser_defaults,
    );
    Getopt::Long::Configure qw(no_getopt_compat permute bundling);
    Getopt::Long::GetOptions(\%opts, @switches) or pod2usage(2);

    if ($opts{help}) {
        pod2usage(1);
    }
    if ($opts{version}) {
        my $version = q{$Id$};
        print qq{$0 version $version\n};
        exit 0;
    }

    # Separate logparser and ASO::Parser options.
    my (%logparser, %parser);
    foreach my $option (keys %opts) {
        if (exists $logparser_defaults{$option}) {
            $logparser{$option} = $opts{$option};
        } else {
            $parser{$option} = $opts{$option};
        }
    }

    return (\%logparser, \%parser);
}

# Convert keys from Getopt::Long option specifiers to option names.
sub getopt_to_key {
    my (%opts) = @_;
    my %names;

    map {
        my ($key, $value) = ($_, $opts{$_});
        $key =~ s/[!|=].*//;
        $names{$key} = $value;
    } keys %opts;

    %names;
}

sub timewarn {
    warn qq{$0: }, scalar localtime, q{: }, @_;
}

sub print_timing {
    my ($message, $filename, $interval) = @_;
    if ($Options->{q{timing-data}}) {
        printf $timing_file qq{$message: $filename: %.6f\n}, $interval;
    }
}

=pod

=head1 NAME

logparser - parse Postfix log files

=head1 VERSION

This documentation refers to logparser version $Id$

=head1 SYNOPSIS

    # Parse mail.log.1
    logparser mail.log.1
    # Parse mail.log.4, mail.log.3 and mail.log.2; save state to parser-state
    logparser --out-statefile parser-state mail.log.3 mail.log.2
    # Parse mail.log.1, loading state from the previous run
    logparser --in-statefile parser-state mail.log.1

    # Parse mail.log.1 without inserting results in the database to improve 
    # speed when testing new rules; also use a different database.
    logparser --skip_inserting_results --data_source 'dbi:SQLite:dbname=test-db.sq3' mail.log.1

=head1 DESCRIPTION

logparser is a thin wrapper around L<ASO::Parser> - it handles parsing of
multiple files, saving and loading state, plus any other housekeeping required
by L<ASO::Parser>.  It also performs various profiling related tasks, depending
on the profiling module, if any, in use.

=head1 OPTIONS

Defaults are equivalent to:
    logparser --out-statefile 'state' \
              --data_source 'dbi:SQLite:dbname=../sql/db.sq3'

=over 4

=item --in-statefile FILE, -i FILE

Load state from a previous run from FILE.

=item --out-statefile FILE, -o FILE

Save state from this run to FILE.  If this option is not given state will be
saved to a file named 'state' in the current directory.

=item --data_source STRING

Specifies the database to use when loading rules and saving results.  Defaults
to 'dbi:SQLite:dbname=../sql/db.sq3'.  See L<DBI> for more information about the
format of this option.

=item --username USERNAME

The password to use when connecting to the database.

=item --password PASSWORD

The username to use when connecting to the database.

=item --year YEAR

When parsing log lines from previous years you must specify the year the log
lines are from.

Parse::Syslog will discard log lines which appear to come from the future.  If
today is 2008/01/01, and you're parsing log lines from 2007/06/01, the syslog
parser will assume the log line is from B<2008>/06/01 (because the year is not
included in the log line), decide it's from the future, and discard it.

=back



=head1 DEBUGGING OPTIONS

These options are not necessary for normal use, they are provided for debugging
new rules or the parser itself.

=over 4

=item --sort_rules normal|shuffle|reverse

Whether to sort the rules for maximum efficiency (normal), minimal efficiency
(reverse), or randomly (shuffle).  Run time increases by about 20% when using
reverse sorting, though it is highly data dependant.  This is useful for
detecting overlapping rules: you should get exactly the same results in the
database regardless of which ordering you use - if the results change it's an
indication you have overlapping rules.

=item --discard_compiled_regex

By default every rule's regex is compiled once and cached; this switch disables
that caching so each regex is compiled every time it's used.  This incurs
approximately a 450% increase in run time, though again it's data dependant.
The main use for this option is when generating data to show how much slower the
parser is without caching of compiled regexs, though it may be possible that a
sufficiently complicated regex may require re-compilation each time it is used
(if you can come up with such a regex please inform the author).

=item --skip_inserting_results

Inserting results into the database is slow because of the additional disk or
network IO required, causing a huge slowdown in execution.  When testing new
rules or parser features disabling insertion of results is essential for a quick
testing cycle.  Default is to inset results.

=item --parse_lines_only

Parse log lines, but don't run the rule's action.  Useful for testing new rules,
as no new data will be added to the database but warnings will still be issued
for unparsed lines.  Execution is also much faster.  Default is to run actions.

=item --print_matching_regex

Print the regex and the line on each successful match, in the format:

  REGEX !!!! LINE

This might be useful to verify that a line is being matched by the regex you
expect.  This option still takes effect when B<--parse_lines_only> is specified.

=item --debug_results

Save extra data in each result to aid in debugging.  The data will not be stored
in the database, but it will be shown when connections are dumped for any
reason.  There is extra memory overhead associated with saving this data, and
a slight run time increase.  Default is to save the minimum data required.

=item --dump_committed_connections

Dump each connection that is committed.  This might be useful for serious
debugging, or verifying the parser's behaviour after changing the parser or
rules.  This will take effect even if --skip_inserting_results has been
specified.

=item --timing-data FILE

Save timing data to FILE.

=back

=head1 CONFIGURATION AND ENVIRONMENT

A database containing rules and results is required, created by running:

    perl setup-database create-tables-sqlite3-generated.sql populate-rules.sql

This will create an SQLite3 database containing the required tables and the
default rules.  You can obviously use a different database, but you'll need to
adapt the SQL appropriately.  If you do this please send me the new SQL and I'll
add it to the distribution.

=head1 DEPENDENCIES

Modules packaged with logparser: ASO::DB, ASO::Parser (both have additional
dependencies, see their documentation for details).

Standard Perl modules: Getopt::Long, Pod::Usage, File::Temp.

=head1 INCOMPATIBILITIES

None known.

=head1 BUGS AND LIMITATIONS

None known.  Bug reports and optionally patches welcome.

=head1 AUTHOR

John Tobin <tobinjt@cs.tcd.ie>

=head1 LICENCE AND COPYRIGHT

Copyright (c) 2006-2007 John Tobin <tobinjt@cs.tcd.ie>.  All rights reserved.

This module is free software; you can redistribute it and/or
modify it under the same terms as Perl itself. See L<perlartistic>.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 

=cut

