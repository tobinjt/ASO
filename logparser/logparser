#!/usr/bin/env perl

# $Id$

use strict;
use warnings;

use lib q{..};
use ASO::DB;
use Parse::Syslog;
use IO::File;
use Carp;
use Data::Dumper;
use Regexp::Common qw(Email::Address net);

my $dbix = ASO::DB->connect(
    q{dbi:SQLite:dbname=../sql/db.sq3},
    {AutoCommit => 0},
);

my @logs = @ARGV;
if (not @logs and -t STDIN) {
    die qq{Usage: $0 logfile [logfiles]\n};
}
if (not @logs) {
    @logs = q{-};
}

my @checks      = process_checks();
my @parse_rules = process_parse_rules();
my $restriction_start = filter_regex(
    qr/^([A-Z0-9]{9}|NOQUEUE): (reject(?:_warning)?): (?:RCPT|DATA) from (?>(__HOSTNAME__)\[)(?>(__IP__)\]): (__SMTP_CODE__) /
);
$restriction_start = qr/$restriction_start/;

my %connections = ();
my %count = ();
my $num_connections_uncommitted;
foreach my $logfile (@logs) {
    my $syslog = Parse::Syslog->new($logfile);
    if (not $syslog) {
        croak qq{Failed creating parser for $logfile: $@\n};
    }

    LINE:
    while (my $line = $syslog->next()) {
        if ($line->{program} !~ m/^postfix\/smtpd/) {
            # It's not from postfix, ignore it.
            next LINE;
        }
        if (not defined $line->{pid}) {
            # For some weird reason there's no PID.  Probably a line like:
            # "refreshing the Postfix mail system"
            next LINE;
        }

        RULE:
        foreach my $rule (@parse_rules) {
            if ($line->{text} !~ m/$rule->{regex}/) {
                next RULE;
            }

            # A line we want to ignore
            if (uc $rule->{action} eq q{IGNORE}) {
                next LINE;
            }

            # Someone has connected to us
            if (uc $rule->{action} eq q{CONNECT}) {
                make_connection($line, $logfile);
                next LINE;
            }

            # Someone has disconnected
            if (uc $rule->{action} eq q{DISCONNECT}) {
                disconnection($line, $logfile);
                next LINE;
            }
        }

        # Parse::Syslog handles "last line repeated n times" by returning the 
        # same hash as it did on the last call, so any changes we make to the 
        # contents of the hash will be propogated, thus we need to work on a
        # copy of the text of the line from now on, as we'll be making changes
        # to it.
        my $text = $line->{text};

        # The start of every restriction line is the same, so strip it off here
        if ($text !~ s/$restriction_start//) {
            print qq{line doesn't match restriction_start: $logfile: $.: $text\n};
            next LINE;
        }
        my ($queueid, $result, $hostname, $ip, $smtp_code)
         = ($1,       $2,      $3,        $4,  $5        );

        CHECK:
        foreach my $check (@checks) {
            my @matches = ($text =~ m/$check->{regex}/);
            if (not @matches) {
                next CHECK;
            }
            # regex matches are 1-based, but arrays are 0-based.
            # unshift undef onto the start of the array to align the two.
            unshift @matches, undef;
            $count{$check->{name}}++;

            # Deal with the lack of connection lines sometimes.
            if (not $connections{$line->{pid}}) {
                make_connection($line, $logfile);
            }

            $connections{$line->{pid}}->{connection}->ip($ip);
            $connections{$line->{pid}}->{connection}->hostname($hostname);
            $connections{$line->{pid}}->{connection}->helo(
                $matches[$check->{connection_cols}->{helo}]
            );

            my $check_result = $dbix->resultset(q{Check::Result})->new_result({
                check_id        => $check->{id},
                result          => $result,
#                warning         => 
                smtp_code       => $smtp_code,
                recipient       => $matches[$check->{result_cols}->{recipient}],
                sender          => $matches[$check->{result_cols}->{sender}],
                log_line        => $line->{text},
                data            => $matches[$check->{result_cols}->{data}],
            });

            push @{$connections{$line->{pid}}->{results}}, $check_result;

            next LINE;
        }

        # Last ditch: complain to the user
        #print qq{unknown line: $logfile: $.: $text\n};
        print qq{Nov  5 00:00:10 relay.cs.tcd.ie postfix/smtpd[21407]: [ID 197553 mail.info] $line->{text}\n};
    }
}
if ($num_connections_uncommitted) {
    $dbix->txn_commit();
}

print Dumper(\%count);

sub parse_result_cols {
    my ($spec) = @_;

    my $assignments = {};
    foreach my $assign (split /\s*,\s*/, $spec) {
        if (not length $assign) {
            croak qq{empty assignment found in: $assignments\n};
        }
        if ($assign !~ m/^\s*(\w+)\s*=\s*(\d+)\s*/) {
            croak qq{bad assignment: $assign\n};
        }
        $assignments->{$1} = $2;
    }
    return $assignments;
}

sub compile_regex {
    my ($object) = @_;
    my $regex = filter_regex($object->regex());
    my $compiled_regex;
    eval {
        $compiled_regex = qr/$regex/;
    };
    if ($@) {
        my %columns = $object->get_columns();
        croak qq{$0: failed to compile regex $regex: $@\n}
            . Data::Dumper->Dump([\%columns], [qw(row)]);
    }
    return $compiled_regex;
}

sub process_parse_rules {
    my @results;
    foreach my $rule ($dbix->resultset(q{ParseRule})->search()) {
        my $rule_hash = {};
        $rule_hash->{id}                = $rule->id();
        $rule_hash->{action}            = $rule->action();
        $rule_hash->{rule_order}        = $rule->rule_order();
        # Compile the regex for efficiency, otherwise it'll be recompiled every
        # time it's used.
        $rule_hash->{regex}             = compile_regex($rule);
        push @results, $rule_hash;
    }
    return sort { $a->{rule_order} <=> $b->{rule_order} } @results;   
}

sub process_checks {
    my @results;
    foreach my $check ($dbix->resultset(q{Check})->search()) {
        my $check_hash = {};
        $check_hash->{id}               = $check->id();
        $check_hash->{name}             = $check->name();
        $check_hash->{check_order}      = $check->check_order();
        # Compile the regex for efficiency, otherwise it'll be recompiled every
        # time it's used.
        $check_hash->{regex}            = compile_regex($check);
        eval {
            $check_hash->{result_cols}      = parse_result_cols($check->result_cols());
            $check_hash->{connection_cols}  
                = parse_result_cols($check->connection_cols());
        };
        if ($@) {
            croak $@ . Dumper($check_hash);
        }
        if (not exists $check_hash->{result_cols}->{data}) {
            $check_hash->{result_cols}->{data} = 0;
        }
        push @results, $check_hash;
    }
    return sort { $a->{check_order} <=> $b->{check_order} } @results;
}

sub filter_regex {
    my ($regex) = @_;

    # I'm deliberately allowing a trailing .
    my $hostname_re = qr/(?:unknown|(?:[-_a-zA-Z0-9.]+))/;

    $regex =~ s/__SENDER__      /__EMAIL__/gx;
    $regex =~ s/__RECIPIENT__   /__EMAIL__/gx;
    # We see some pretty screwey hostnames in HELO commands.
    $regex =~ s/__HELO__        /__HOSTNAME__|(?:\\[)__IP__(?:\\])|(.*?)/gx;
#   $regex =~ s/__EMAIL__       /$RE{Email}{Address}/gx;
#   The empty alternative below is to allow for <> as the sender address
#   We also allow up to 7 @ signs in the address . . . I have seen that many :(
    $regex =~ s/__EMAIL__       /(?:|[^@]+(?:\@(?:__HOSTNAME__|\\[__IP__\\])){0,7})/gx;
    #$regex =~ s/__HOSTNAME__    /$RE{net}{domain}{-nospace}/gx;
    $regex =~ s/__HOSTNAME__    /$hostname_re/gx;
    $regex =~ s/__IP__          /$RE{net}{IPv4}/gx;
    $regex =~ s/__SMTP_CODE__   /\\d{3}/gx;
#   $regex =~ s/____/$RE{}{}/g;

    return $regex;
}

sub make_connection {
    my ($line, $logfile) = @_;

    if (exists $connections{$line->{pid}}) {
        carp <<"COMPLAINT";
$0: $logfile: $.: existing connection hash for pid $line->{pid}; this should never happen :(
COMPLAINT
    }
    $connections{$line->{pid}} = {};
    $connections{$line->{pid}}->{connection} =
        $dbix->resultset(q{Connection})->new_result({
            start => $line->{timestamp}
        });
    $connections{$line->{pid}}->{results} = [];
}

sub disconnection {
    my ($line, $logfile) = @_;

    if (not exists $connections{$line->{pid}}) {
        warn <<"COMPLAINT";
$0: $logfile: $.: no connection hash for pid $line->{pid} - perhaps the connect line is in a previous log file?
COMPLAINT
        return;
    }

    # We're not dealing with success; need to add that later.
    if (not @{$connections{$line->{pid}}->{results}}) {
        delete $connections{$line->{pid}};
        return;
    }

    if ($num_connections_uncommitted > 1000) {
        $dbix->txn_commit();
        $num_connections_uncommitted = 0;
    }
    if (not $num_connections_uncommitted) {
        $dbix->txn_begin();
    }

    my $connection = $connections{$line->{pid}}->{connection};
    $connection->end($line->{timestamp});
    $connection->insert();
    $num_connections_uncommitted++;

    foreach my $result (@{$connections{$line->{pid}}->{results}}) {
        $result->connection_id($connection->id());
        $result->insert();
    }

    delete $connections{$line->{pid}};
}
