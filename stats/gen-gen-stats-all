#!/usr/bin/env perl

# This will generate gen-stats-all, ensuring that all option combinations are
# used when generating stats.

# $Id$

use strict;
use warnings;

use IO::File;
use Storable qw(dclone);

my $filename = q{gen-stats-all};
my $fh = IO::File->new(q{> } . $filename)
    or die qq{$0: failed opening $filename: $!};

print $fh <<'PRELUDE';
#!/bin/bash

set -u -e

# Start by doing a straight test run, to get a baseline idea of parsing speed.

full_run_dir="/home/tobinjt/results/results-full-run"
mkdir -p "$full_run_dir"
cp -p ../sql/db.maximum-ruleset.sq3 ../sql/db.sq3
perl ../logparser/logparser --year 2007 --skip_inserting_results \
    --out-statefile "$full_run_dir/state" --individual-state-files \
    --timing-data "$full_run_dir/timing" \
    --out-rule-order "$full_run_dir/rule-order" --individual-rule-order-files \
    $( < ../logparser/logs-some ) 2> "$full_run_dir/warnings"
rule_order_dir="$full_run_dir/../rule_order"
mkdir -p "$rule_order_dir"
cp -f "$full_run_dir/"rule-order* "$rule_order_dir"

# Now insert results, to see how that affects speed.

insert_results_dir="/home/tobinjt/results/results-insert-results"
mkdir -p "$insert_results_dir"
cp -p ../sql/db.maximum-ruleset.sq3 ../sql/db.sq3
perl ../logparser/logparser --year 2007 \
    --out-statefile "$insert_results_dir/state" --individual-state-files \
    --timing-data "$insert_results_dir/timing" \
    --out-rule-order "$insert_results_dir/rule-order" --individual-rule-order-files \
    $( < ../logparser/logs-some ) 2> "$insert_results_dir/warnings"

# Now do all the combinations.
PRELUDE

# Options:
# * Always discard results: we're testing the parser, not the database and hard
#   disk.
# * Caching of regexes
# * Rule ordering, including perfect best and perfect worst.
#
# Plus minimum versus maximum rule sets for each combination of options.
# Plus parsing only, as a special case.

my @options = (
    {
        skip_inserting_results      => q{--skip_inserting_results},
    },
    {
        cache_compiled_regexes      => q{},
        discard_compiled_regexes    => q{--discard_compiled_regex},
    },
    {
        perfect_best                => q{--perfect-rule-order=best},
        optimal_ordering            => q{--sort_rules=optimal},
        shuffle_ordering            => q{--sort_rules=shuffle},
        reverse_ordering            => q{--sort_rules=reverse},
        perfect_worst               => q{--perfect-rule-order=worst},
    },
);

my @arguments = (
    {
        minimum_ruleset             => q{../sql/db.minimum-ruleset.sq3},
        maximum_ruleset             => q{../sql/db.maximum-ruleset.sq3},
    },
);

my %parsing_only = (
    options     => [qw( --skip_inserting_results
                        --sort_rules=optimal
                        --parse_lines_only
                    )],
    arguments   => [q{../sql/db.maximum-ruleset.sq3}],
    directory   => [qw( skip_inserting_results
                        cache_compiled_regexes
                        optimal_ordering
                        parse_lines_only
                    )],
);

#use Data::Dumper;
my @mega_results = add_options(\@options, \@arguments, {});
push @mega_results, \%parsing_only;
#print Dumper(\@mega_results);

print_commands($fh, \@mega_results);
my $num_test_runs = scalar @mega_results;
print qq{$num_test_runs test runs with different options\n};

sub add_options {
    my ($options, $arguments, $results) = @_;

    if (not @{$options}) {
        return add_arguments($arguments, $results);
    }
    $results->{options}     ||= [];
    $results->{directory}   ||= [];

    my @all_results;
    my $remaining_options = dclone($options);
    my $option_list = shift @{$remaining_options};

    foreach my $option (sort keys %{$option_list}) {
        my $results_copy = dclone($results);
        push @{$results_copy->{options}}, $option_list->{$option};
        push @{$results_copy->{directory}}, $option;
        push @all_results,
            add_options($remaining_options, $arguments, $results_copy);
    }

    return @all_results;
}

sub add_arguments {
    my ($arguments, $results) = @_;

    if (not @{$arguments}) {
        return $results;
    }
    $results->{arguments}   ||= [];
    $results->{directory}   ||= [];

    my @all_results;
    my $remaining_arguments = dclone($arguments);
    my $argument_list = shift @{$remaining_arguments};

    foreach my $argument (sort keys %{$argument_list}) {
        my $results_copy = dclone($results);
        push @{$results_copy->{arguments}}, $argument_list->{$argument};
        push @{$results_copy->{directory}}, $argument;
        push @all_results, add_arguments($remaining_arguments, $results_copy);
    }

    return @all_results;
}

sub print_commands {
    my ($fh, $all_results) = @_;

    foreach my $result (@{$all_results}) {
        my $options   = join q{ }, @{$result->{options}};
        my $arguments = join q{ }, @{$result->{arguments}};
        my $directory = join q{--}, q{/home/tobinjt/results/results}, @{$result->{directory}};
        print $fh <<"COMMAND";
if [ ! -d "$directory" ]; then
    LOGPARSER_SWITCHES="$options" bash ../stats/gen-stats "$directory" $arguments
else
    echo "Skipping existing directory $directory"
fi
COMMAND
    }
}
