#!/usr/bin/env perl

# This will generate gen-stats-all, ensuring that all option combinations are
# used when generating stats.

# $Id$

use strict;
use warnings;

use IO::File;
use Storable qw(dclone);

my $filename = q{gen-stats-all};
my $fh = IO::File->new(q{> } . $filename)
    or die qq{$0: failed opening $filename: $!};

print $fh <<'PRELUDE';
#!/bin/bash

set -u -e

# Start by doing a straight test run, to get a baseline idea of parsing speed.

full_run_dir="/home/tobinjt/results/results-full-run"
mkdir -p "$full_run_dir"
cp -p ../sql/db.maximum-ruleset.sq3 ../sql/db.sq3
perl ../logparser/logparser --year 2007 --skip_inserting_results \
    --out-statefile "$full_run_dir/state" --individual-state-files \
    --timing-data "$full_run_dir/timing" \
    --out-rule-order "$full_run_dir/rule-order" --individual-rule-order-files \
    $( < ../logparser/logs-some ) 2> "$full_run_dir/warnings"
rule_order_dir="$full_run_dir/../rule_order"
mkdir -p "$rule_order_dir"
cp -f "$full_run_dir/"rule-order* "$rule_order_dir"

# Now insert results, to see how that affects speed.

insert_results_dir="/home/tobinjt/results/results-insert-results"
mkdir -p "$insert_results_dir"
cp -p ../sql/db.maximum-ruleset.sq3 ../sql/db.sq3
perl ../logparser/logparser --year 2007 \
    --out-statefile "$insert_results_dir/state" --individual-state-files \
    --timing-data "$insert_results_dir/timing" \
    --out-rule-order "$insert_results_dir/rule-order" --individual-rule-order-files \
    $( < ../logparser/logs-some ) 2> "$insert_results_dir/warnings"

# Now do all the combinations.
PRELUDE

# Options:
# * Always discard results: we're testing the parser, not the database and hard
#   disk.
# * Caching of regexes
# * Rule ordering, including perfect best and perfect worst.
#
# Plus minimum versus maximum rule sets for each combination of options.
# Plus parsing only, as a special case.

my %options = (
        perfect_best                => q{--perfect-rule-order=best},
        optimal_ordering            => q{--sort_rules=optimal},
        shuffle_ordering            => q{--sort_rules=shuffle},
        reverse_ordering            => q{--sort_rules=reverse},
        perfect_worst               => q{--perfect-rule-order=worst},
);

my @arguments = (
    {
        minimum_ruleset             => q{../sql/db.minimum-ruleset.sq3},
        maximum_ruleset             => q{../sql/db.maximum-ruleset.sq3},
    },
);

my %template = (
    options     => [q{--sort_rules=optimal}],
    arguments   => q{../sql/db.maximum-ruleset.sq3},
    directory   => [q{optimal_ordering}],
);
# Parsing only:
my $parsing_only = dclone(\%template);
push @{$parsing_only->{options}}, q{--parse_lines_only};
push @{$parsing_only->{directory}}, q{parse_lines_only};
# Discarding compiled regexes.
my $discarding_regexes = dclone(\%template);
push @{$discarding_regexes->{options}}, q{--discard_compiled_regex};
push @{$discarding_regexes->{directory}}, q{discard_compiled_regexes};

#use Data::Dumper;
my @mega_results = add_options(\%options, \@arguments, {});
push @mega_results, $parsing_only;
push @mega_results, $discarding_regexes;
#print Dumper(\@mega_results);

print_commands($fh, \@mega_results);
my $num_test_runs = scalar @mega_results;
print qq{$num_test_runs test runs with different options\n};

sub add_options {
    my ($options, $arguments, $results) = @_;

    $results->{options}     ||= [];
    $results->{directory}   ||= [];

    my @all_results;

    foreach my $option (sort keys %{$options}) {
        my $results_copy = dclone($results);
        push @{$results_copy->{options}}, $options->{$option};
        push @{$results_copy->{directory}}, $option;
        push @all_results, $results_copy;
    }

    my @real_results;
    foreach my $result (@all_results) {
        my $minimum = dclone($result);
        $minimum->{arguments} = q{../sql/db.minimum-ruleset.sq3};
        push @{$minimum->{directory}}, q{minimum_ruleset};
        push @real_results, $minimum;

        my $maximum = dclone($result);
        $maximum->{arguments} = q{../sql/db.maximum-ruleset.sq3};
        push @{$maximum->{directory}}, q{maximum_ruleset};
        push @real_results, $maximum;
    }
    return @real_results;
}

sub print_commands {
    my ($fh, $all_results) = @_;

    my @runs;
    push @runs, grep { $_->{arguments} =~ m/min/ } @{$all_results};
    push @runs, grep { $_->{arguments} =~ m/max/ } @{$all_results};

    foreach my $result (@runs) {
        my $options   = join q{ }, @{$result->{options}};
        my $arguments = $result->{arguments};
        my $directory = join q{--}, q{/home/tobinjt/results/results}, @{$result->{directory}};
        print $fh <<"COMMAND";
if [ ! -d "$directory" ]; then
    LOGPARSER_SWITCHES="$options" bash ../stats/gen-stats "$directory" $arguments
else
    echo "Skipping existing directory $directory"
fi
COMMAND
    }
}
